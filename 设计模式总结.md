### ***设计模式总结：***

####  创建型

- 单例模式：用来创建全局唯一的对象。在Go语言中，可以使用sync.Once和包级别的变量来实现单例模式。
- 工厂模式：用来创建不同但是相关类型的对象（继承同一父类或者接口的一组子类），由给定的参数来决定创建哪种类型的对象。在Go语言中，可以使用接口和结构体来实现工厂模式。
- 建造者模式：用来创建复杂对象，可以通过设置不同的可选参数，“定制化”地创建不同的对象。

​	

####  结构型

- 代理模式：是一种结构型设计模式，用于为对象提供一个代理或占位符，从而控制对实际对象的访问。
- 桥接模式：是一种结构型设计模式，用于将抽象与实现解耦，使得两者可以独立地变化。
- 适配器模式：是一种结构型设计模式，用于将一个类的接口转换为客户端期望的另一个接口。这样，原本接口不兼容的类可以一起工作。
- 装饰器模式：是一种结构型设计模式，用于在不改变原始对象的基础上，动态地给对象添加新的功能。

​	

####  行为型

- 观察者模式：也被称为发布订阅模式，在对象之间定义一个一对多的依赖，当一个对象状态改变的时候，所有依赖的对象都会自动收到通知。



### 购物车项目介绍：

首先，直播购物车功能的核心需求是让用户在观看直播的过程中能够方便地下单支付购物车中的商品，同时具备优惠卷推送、领取、结算时使用的能力。为了实现这个需求，我们设计了一个包括商品信息管理、购物车商品状态管理、限量库存同步、优惠券分发和订单结算等模块的后端服务。在设计过程中，我们特别关注了系统的性能、可扩展性和可维护性。


在开发过程中，我们遇到了一些挑战和难点。

首先是购物车状态的实时同步问题。为了解决这个问题，我们采用了广播推送和下单拉取的双重，确保用户下单的时候购物车是最新的状态。

其次是限购的库存一致性问题。为了保证库存的一致性限量商品不超买，我们使用了定时任务和redis eval脚本的操作，锁单过程中判断当前购买数+已售出数+锁库存数的和是否大于总售数，并且通过定时任务自动释放掉超时未支付的订单。

再就是优惠券的推送逻辑。我们需要在高并发场景下保证优惠券的正确分发和使用，避免超额发放。为此，我们采用了分布式锁来保证优惠券的一致性，推送包括人工推送和自动推送，推送时会先获取一个房间维度的分布式锁过期时间设置为优惠卷前端展示的时间，避免重复或者多推，推送成功则更新数据库推送状态和推送时间，后续任务不会再进行推送；推送失败只更新数据库推送状态，这里如果数据库状态更新失败，则需要删除掉分布式锁，让其他机器能够获取到锁进行推送。

开发过程中，我们还进行了一些优化和改进。例如，redis pipeline操作减少和redis的交互通信次数，降低延迟。由于redis集群采用是多节点部署的方式，Pipeline是对多个key是需要通过使用标签，让所有操作落到同一个节点node上，保证快速性，避免key落在不同节点之间导致的通信。使用分表分页拉去逻辑存储和获取用户的订单信息，提高整体系统的响应速度。

重复订单回调是通过对回调的订单号做redis标识校验来过滤重复回调的。优惠券是对应多个商品都可以使用的。

同一张优惠券会不会多次有效，更新db失败。

弹幕抽奖，抛kafaka之后，进激奖池前会判断奖池是否已经锁奖池了，通过判断当前时间和配置的时间（配置的时间是定时任务在拉数据库写入本地缓存中，直接本地缓存获取）。

  

***\*派危后端一面：\****

**1*****\*、redis分布式存储的过程中，如果使用的pipeline怎么保证所有的key到同一个node槽上去。\****

在 Redis 集群模式下，如果想让多个 key 落在同一个槽（slot）上，以便在 pipeline 操作中一起处理，你可以使用哈希标签（hash tags）来实现。哈希标签是将大括号 {} 包含的部分作为 key 的一部分，Redis 会根据这部分内容来计算槽。这样，具有相同哈希标签的 key 会被映射到同一个槽上。

 

***\*2、go语言的CAS和CSP\****

CAS 是一种原子操作，用于在多线程或多协程环境中安全地更新共享变量。CAS 操作会比较当前变量值和预期值，如果它们相等，则将变量更新为新值。这个过程是原子的，即在执行过程中不会被其他线程或协程中断。Go 语言的 sync/atomic 包提供了一系列 CAS 操作，例如 atomic.CompareAndSwapInt32

CSP 是一种并发编程模型，它强调通过通信（communication）来共享内存，而不是通过共享内存来通信。Go 语言的并发模型基于 CSP，它使用协程（goroutine）和通道（channel）来实现并发编程。协程是轻量级的线程，可以并发执行，而通道是一种同步机制，用于在协程之间传递数据。

总之：CAS 是一种原子操作，用于安全地更新共享变量；CSP 是 Go 语言的并发编程模型，它使用协程和通道来实现并发。

 

***3.说一下go语言的G\*******\*MP\*******\*模型\****

G - Goroutine，Go协程，是参与调度与执行的最小单位

M - Machine，指的是系统级线程

P - Processor，指的是逻辑处理器，P关联了的本地可运行G的队列(也称为LRQ)，最多可存放256个G。

总结：M想要运行线程任务时，先绑定一个P，P看看自己本地的队列有没有G，没有的话就去全局G队列取一些来，如果全局也没有话，就随机从其他P的本地队列偷一半过来。

拿到可运行的G之后，M运行G,G执行之后，M会从P获取下一个G，不断重复下去。

 

***\*4、websockt的了解\****

WebSocket 是一种网络通信协议，它提供了在单个长连接中进行全双工（full-duplex）通信的能力。WebSocket 使得客户端和服务器之间可以在任何时候互相发送消息，而不需要像 HTTP 请求那样每次都建立一个新的连接。这有助于减少延迟，并提高实时性能，特别适用于实时应用程序，如在线聊天、游戏、实时数据传输等场景。

双向通信：WebSocket 支持全双工通信，这意味着客户端和服务器可以同时发送和接收消息，而不需要建立新的连接。这有助于减少通信延迟，并提高应用程序的实时性能。

基于帧的数据传输：WebSocket 协议使用帧（frames）来传输数据。

与 HTTP 兼容：WebSocket 协议使用相同的端口（80 和 443）作为 HTTP 和 HTTPS。

低开销：与 HTTP 相比，WebSocket 协议的开销要小得多。一旦建立连接，数据帧的头部只有几个字节，而不是几百字节的 HTTP 头部。这有助于减少网络流量，提高传输效率。

浏览器支持：大多数现代浏览器都支持 WebSocket API，这使得在 Web 应用程序中使用 WebSocket 变得非常方便。

 

***5介绍一下当前使用的推送方式，也就是mcp那套框架。***

当前使用时是原QQTalk（简称QT）产品部自研的一套高性能的网络服务器框架。跟多线程的开发框架不同，框架主要采用的是多进程加协程的框架模式。

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps1.jpg) 

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps2.jpg)![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps3.jpg) 

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps4.jpg)![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps5.jpg) 

其中CCD负责网络前端收发、MCD负责业务逻辑处理，SubMCD也是MCD的进程，业务较复杂时可以由MCD分发给多个SubMCD进行处理，而DCC负责网络后端收发。进程间通信通过两个单向管道（MQ）实现，通过write 操作触发epoll 事件驱动整个框架运转。

 

***\*6、项目上有没有遇到过什么疑难杂症去排查问题（提前准备好两个例子）\****

第一个：body丢失的问题，框架上导致body为空了。
第二个：open too many file。

 

 

 

***\*7、线上CPU飙升，怎么排查相关的问题（列出详细流程来）\****

可以用top、pidstat 等工具找到占用CPU的进程。

GDB常常是用来排查后期，根据core文件来处理定位问题的异常出现原因。

使用 perf 分析 CPU 性能问题！

第一种常见用法是 perf top

类似于 top，它能够实时显示占用 CPU 时钟最多的函数或者指令，因此可以用来查找热点函数。

第二种常见用法，也就是 perf record 和 perf report

perf top 虽然实时展示了系统的性能信息，但它的缺点是并不保存数据，也就无法用于离线或者后续的分析。而 perf record则提供了保存数据的功能，保存后的数据，需要你用 perf report 解析展示。

***\*`\*******\*``\****

$ perf record # 按Ctrl+C终止采样

[ perf record: Woken up 1 times to write data ]

[ perf record: Captured and wrote 0.452 MB perf.data (6093 samples) ]

$ perf report # 展示类似于perf top的报告

***\*`\*******\*``\****

在实际使用中，我们还经常为 perf top 和 perf record 加上 -g 参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。

perf top -g -p PID

这条命令的作用是实时显示指定进程（PID）的 CPU 使用情况，并以调用图（call-graph）的形式展示。这可以帮助你理解程序的执行流程，找出 CPU 使用高的函数，优化程序的性能。

pstree 或者 execsnoop

碰到常规问题无法解释的 CPU 使用率情况时，首先要想到有可能是短时应用导致的问题，比如有可能是下面这两种情况。

第一，应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过 top 等工具也不容易发现。

第二，应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的 CPU。

总结：对于这类进程，我们可以用 pstree 或者 execsnoop 找到它们的父进程，再从父进程所在的应用入手，排查问题的根源。

 

***\*8、go语言如果gc mark占用的太多了，应该怎么排查处理\****

在 Go 语言中，垃圾回收（GC）的过程可能会导致程序暂停。如果你发现 GC mark 阶段占用的时间太多，可以采取以下方法进行排查和处理：

1、先使用pprof分析内存是不是有泄露，或者不必要的内存分配操作

2、减少内存分配，***\*a.\****优化数据结构和算法，以减少内存分配。b.复用对象，避免频繁创建和销毁对象。例如，使用 sync.Pool 来复用临时对象。c.避免在循环中分配内存，尽量在循环外部分配内存并在循环内部复用。d.使用缓冲区（buffer）来减少内存分配，例如 bytes.Buffer 或 strings.Builder。

3、调整垃圾回收器参数：Go 语言允许你调整垃圾回收器的行为，以减少 GC 停顿时间。例如，你可以通过设置 GOGC 环境变量

 

***\*9、题目：\****

***\*a. 开启N个协程并发执行任务,等待所有协程执行结束后退出.不可以使用sync.WaitGroup\****

```go
package main

import (
		"fmt"
		"time"
)

 

func main() {

		numGoroutines := 5

	done := make(chan bool, numGoroutines)


	// 启动 N 个协程

		for i := 0; i < numGoroutines; i++ {
			go func(id int) {
				fmt.Printf("Goroutine %d started\n", id)

				time.Sleep(time.Duration(id) * time.Second) // 模拟任务执行时间

				fmt.Printf("Goroutine %d finished\n", id)

				done <- true

			}(i)

		}


		// 等待所有协程执行结束

		for i := 0; i < numGoroutines; i++ {
			<-done
		}

		fmt.Println("All goroutines finished")
	}
```

 

***\*b. 开启M个协程并发执行N个任务,等待所有任务执行结束后退出\****

```go
	package main

​	import (

​		"fmt"

​		"sync"

​		"time"

​	)

 

​	func worker(id int, jobs <-chan int, results chan<- int, wg *sync.WaitGroup) {

​		for job := range jobs {

​			fmt.Printf("Worker %d started job %d\n", id, job)

​			time.Sleep(1 * time.Second) // 模拟任务执行时间

​			fmt.Printf("Worker %d finished job %d\n", id, job)

​			results <- job

​		}

​		wg.Done()

​	}

 

​	func main() {

​		numWorkers := 3

​		numJobs := 10

 

​		jobs := make(chan int, numJobs)

​		results := make(chan int, numJobs)

 

​		var wg sync.WaitGroup

 

​		// 启动 M 个协程

​		for w := 0; w < numWorkers; w++ {

​			wg.Add(1)

​			go worker(w, jobs, results, &wg)

​		}

 

​		// 分发 N 个任务

​		for j := 0; j < numJobs; j++ {

​			jobs <- j

​		}

​		close(jobs) // 关闭任务通道，通知协程没有更多任务

 

​		wg.Wait() // 等待所有协程执行结束

 

​		// 处理结果

​		for a := 0; a < numJobs; a++ {

​			<-results

​		}

 

​		fmt.Println("All jobs finished")

​	}
```

 

 

 

 

 

 

 

 

 

 

 

 

 

 

***\*派危后端二面：\****

1***\*、怎么保证的原子性，锁库存加购物车和直接下单两个接口\*******\*，不超售。\****

方案一 前面不判断是否达限购

pipeline：mget(个人已购买数：个人限购商品已购买数、全服限购商品售出)+zcard（库存被锁订单数）->eval中，zadd增加下单数->zcard获取锁单数+get全服已购买数判断是否大于限购数->成功就成功，失败则zrem回退，锁单失败。->支付成功就zrem掉+售出总数加1。

方案二 前面判断是否达限购

pipeline：mget(个人已购买数：个人限购商品已购买数、全服限购商品售出)+zcard（库存被锁订单数）->eval中mget拿到的全服限购售出数判断，当前购买是否已经超出限制了。超出就不下一步。直接eval中，zadd增加锁单数->zcard获取锁单数（包括这次zadd锁单的和之前zadd下单的两部分）+全服已售出数是否大于限购数->成功就成功，失败则zrem回退，锁单失败。->支付成功是zrem掉eval中增加的锁单数+售出总数加1。

​	两种各自的优劣：方案一的优点在于所有操作都在 eval 脚本中进行，可以保证原子性，避免并发问题。这对于在高并发场景下保证数据一致性非常重要。然而，它的缺点是如果全服限购已经超出，仍然会执行 zadd 增加锁单数，这可能会导致不必要的计算开销。 方案二你在执行更重的操作（如锁定库存）之前就进行了全服限购和个人限购的判断，这样可以尽早地发现是否已经超出限购，从而避免不必要的计算开销，提高性能。

 

***\*2.\*******\*为什么没选择记录库存的方式来实现\****

记录库存数的好处：

更直观：库存数直接反映了剩余的库存量，对于库存管理来说更直观。

更快的库存检查：在用户下单时，只需要检查当前的库存数是否大于0，无需计算已售出数和锁定的订单数。

在库存紧张时更高效：当库存接近耗尽时，可以更早地拒绝新的订单，避免不必要的计算和处理。

记录售出数的好处：

更灵活的库存管理：即使库存不会变化，记录售出数的方案也为未来可能的库存变化提供了更大的灵活性。例如，如果将来需要增加库存，只需要修改库存数，而不需要关心已售出数和锁定的订单数。

更容易处理退货和取消订单：当订单被取消或商品被退货时，只需要将售出数减少，而不需要更新库存数。

 

***\*3.这套系统的性能瓶颈是什么\****

记录库Redis 性能瓶颈：由于 Redis 是单线程的，当大量请求同时到达时，Redis 可能会成为性能瓶颈。在这套方案中，主要涉及到 Redis 的操作有 mget、zcard、eval（包括 zadd、zrem 等内部操作）。尽管 Redis 本身具有很高的性能，但在高并发场景下，执行这些操作可能会导致延迟增加。

网络延迟：在高并发场景下，网络延迟可能会成为性能瓶颈。为了减少网络延迟，可以考虑使用负载均衡器将请求分发到多台服务器，从而分散网络压力。

服务器资源限制：定时任务抢占CPU资源。在高并发场景下，服务器的 CPU、内存和磁盘 I/O 可能会成为性能瓶颈。扩展服务器集群。此外，对程序进行性能优化，如减少不必要的计算、优化数据结构和算法等，也有助于降低服务器资源的消耗。

***\*4.定时任务放在工程API接口中为什么。\****

好处：

简化部署：将定时任务和 API 接口放在同一个工程中，可以简化部署和管理的复杂性。你只需要部署和维护一个工程，而不是将它们分开。

资源共享：在同一个工程中，定时任务和 API 接口可以共享代码、配置和其他资源，这可以减少重复代码和配置的维护工作。

容易扩展：通过容器多节点部署，可以方便地扩展服务的容量，提高可用性和性能。当负载增加时，你可以轻松地添加更多的节点来分摊请求。

坏处：

耦合度较高：将定时任务和 API 接口放在同一个工程中，可能会导致它们之间的耦合度较高。这可能会影响代码的可读性和可维护性。

资源争抢：定时任务和 API 接口共享同一个运行环境，可能会导致它们之间的资源争抢。例如，如果定时任务占用了大量的 CPU 或内存资源，可能会影响 API 接口的性能。

定时任务的冲突：在多节点部署的情况下，每个节点上都会运行定时任务。虽然你使用了分布式锁来保证同一时刻只有一个任务在执行删除失效订单数，但这会增加系统的复杂性，并可能导致性能下降。

实际应用中，你可以根据项目规模、资源分配、业务逻辑关联程度和系统扩展性等因素，权衡这些优缺点，选择最合适的布置方式。

 

***\*5.\*******\*用户id是字符串，字符串怎么对1000去模进行hash的。\*******\*知不知道\*******\*murmur3\*******\*哈希算法。\****

​	用的murmur3哈希算法，将字符串转换为字节切片，并将其写入哈希计算器,随机种子固定取0，保证同一个用户每次hash的值是固定的，结果是一个uint32 类型的无符号整数。

 

***\*6.为什么分1000张表，而不是2的整数次幂，那种更好\*******\*
\****分成 2 的整数次幂（例如 1024）通常更好

计算性能：当分表数是 2 的整数次幂时，计算哈希值对分表数取模的操作可以简化为按位与操作。例如，如果分表数是 1024（即 2^10），那么可以使用 hashValue & (1024-1) 来代替 hashValue % 1024。按位与操作比取模操作更快，可以提高计算性能。

扩展性：使用 2 的整数次幂作为分表数可以方便地进行分表扩展。当需要增加分表数量时，只需将分表数翻倍（例如，从 1024 增加到 2048）。这样可以保持数据在新的分表之间的均匀分布，而不会出现数据倾斜的问题。

***\*7.工作后至今，自己的技术成长是什么。\****

Golang 语言技能：在这段时间里，我通过参与多个项目，对 Golang 的语法和特性有了更深入的熟悉和理解，也会关注一些底层实现的逻辑。

项目经验和角色的转变：从参与项目模块的开发，负责特定模块的设计和实现。到作为项目owner，需要整体把控项目开发的进度周期，联调测试等各类节点，对后台开发整体全流程有进一步的熟悉。

技术深度：在一些中间件mysql、redis等通过实际使用接口自己对底层原理的理解学习，整体有了更深的认知。

技术问题解决能力：在项目中，例如遇到了慢查询导、接口超时、CPU陡增等问题的时候，学会了如何逐步分析、定位、处理线上的异常。例如慢查询日志、explain分析sql、perf性能分析指令、GDB调试等工具。

***\*探迹科技一面：\****

**1.** ***\*算法：两数之和，时间复杂度和空间复杂度\****

map[nums[i]] = index，时间复杂度O（N），空间复杂度哦O（N）

**2.** ***\*快速排序描述，时间复杂度和空间复杂度\****

通过枢纽排序，最好O(nlogn) 平均O(nlogn) 最坏O(n^2)

**3.** ***\*介绍一下go协程的底层原理，其实就是说一下\*******\*GMP\*******\*模型\****

m想要运行线程任务时，先绑定一个p，p看看自己本地的队列有没有G，没有的话就去全局G队列取一些来，如果全局也没有话，就随机从其他P的本地队列偷一半过来。拿到可运行的G之后，M运行G,G执行之后，M会从P获取下一个G，不断重复下去。

**4.** ***\*M\*******\*ysql的索引数据结构，\*******\*B+\*******\*和B数的差异和优势\****

已理解

**5.** ***\*索引失效的情况有哪些\****

左或者左右模糊匹配、对索引列使用函数、索引列进行表达式计算、最左匹配原则 

WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。

**6.** ***\*一个联合索引a,b现在查询的时候order a order b，这种情况下a和b会怎么排序\****

a是全局有效的，b是局部有小

**7.** ***\*M\*******\*ysql的主从同步讲一讲，undolog具体的作用\****

undolog、binlog、redolog的作用理解记忆

 

**8.** ***\*有一张表A线上正在增删更新操作，怎么在业务不停的情况下把数据同步到表B中\****

解决这个问题的一种常见方法是使用 MySQL 的 binlog（二进制日志）。在开始全量复制之前，你需要记录下当前的 binlog 位置（也叫做位点）。然后，在全量复制期间，表 A 的所有增删改查操作都会记录到 binlog 中。当全量复制完成后，你可以从记录的 binlog 位置开始，将全量复制期间的所有操作应用到表 B，这样就可以保证表 A 和表 B 的数据一致。

**9.** ***\*缓存与数据库怎么保证一致性\****

先更新数据、再删除缓存。为了防止删除缓存失败，进行重试机制，可以用kafka去处理删除缓存操作，失败就重试，重试也错就告警。

**10.** ***\*缓存数据多节点布置时，不同节点之间是怎么同步的\****

常见分布式算法举例：

Paxos算法是一种基于消息传递的分布式一致性算法，它提供了在分布式系统中达成一致决策的方法。Paxos算法可以容忍一定数量的故障节点，保证系统在非拜占庭错误条件下的一致性。Paxos算法的核心思想是通过多轮投票和决策来达成一致。

Raft算法：Raft算法是一种为分布式系统提供强一致性的算法，它相较于Paxos算法更易于理解和实现。Raft算法通过选举一个领导者（Leader）来协调分布式系统中的所有操作。领导者负责处理客户端的请求并将操作日志复制到其他节点，其他节点（Follower）接收并应用这些日志以保持一致性。

 

 

 

 

 

***\*万兴科技二面：\****

**1.** ***\*目前所在项目组的团队人员配置\****

在。

**2.** ***\*你在入职腾讯之后，整体个人成长的一个总结，结合实际业绩描述\****

在

**3.** ***\*你觉得难度比较大和比较有挑战的项目介绍一下\****

在

**4.** ***\*考虑外部机会的原因\****

在

**5.** ***\*你跟同届入职的同学相比，你的成长速度是快还是慢的\****

在

**6.** ***\*你期待的工作状态和工作氛围是怎么样的\****

在

**7.** ***\*你自己觉得自己在技术上你叫专精的是哪一块\****

在

**8.** ***\*对应的开源代码看过吗\****

在

**9.** ***\*你觉得做好一个高并发大型协同服务的服务端应该关注哪些方面\****

在

 

***\*C\*******\*o\*******\*bo\*******\*一面：\****

**1.** ***\*K\*******\*af\*******\*ka\*******\*怎么保证消费的准确性和不重复\****

准确性：通过ack确认应答机制保证，有三个等级：ack=0发送成功了就算，ack=1发送后leader收到写入磁盘就算成功，ack=all会等待leader和所有同步副本都收到消息发送后所有的IRS都收到才算成功。

​	不重复消费：通过生产者和消费实现消息处理的幂等性，即使消息重复消费或发送，也不会对系统产生副作用。这可以通过为消息分配唯一的标识符，并在处理消息时检查标识符来实现。通过setnx或者mysql主建或唯一键。偏移量管理，消费者应该及时提交偏移量，确保在消费消息时记录消费位置。这可以防止消费者重复消费已经处理过的消息。

 

**2.** ***\*算法题：有效的字符串括号\****

a) 左括号和星号两个栈记录下标值，最后判断是否左括号栈下表都小于星号栈下表

b) 两次遍历，balance判断是不是等于0

 

 

 

 

 

 

 

 

 

***\*七牛云一面：\****

**1.** ***\*项目压测指标详情，\*******\*cpu\*******\*、内存、消耗达到多少，主要消耗在哪里。\****

在面试过程中，讨论如何提升机器负载性能，可以从以下几个方面入手：

\1. 硬件优化：包括增加CPU核心数、增加内存、提升网络带宽、使用更快的硬盘（如 SSD）等。

\2. 软件优化：包括使用更高效的编程语言、更优化的算法、更精简的代码等。针对数据库，可以进行索引优化，查询优化等。

\3. 系统层面优化：包括操作系统参数调优，例如网络参数，文件描述符数量等。对于数据库等存储系统，还可以进行相应的系统级别参数调优。

\4. 架构优化：例如使用负载均衡分发请求，使用缓存减轻数据库压力，使用异步处理减轻服务器压力，使用微服务架构使得服务可以独立扩展等。

\5. 并发和多线程：对于IO密集型应用，可以通过增加并发数来提高系统吞吐量。对于CPU密集型应用，可以使用多线程或者多进程充分利用多核CPU。

\6. 数据结构和算法优化：根据具体业务，选择合适的数据结构和算法，能够显著提升系统性能。

\7. 数据库优化：包括数据库查询优化，索引优化，分表分库，读写分离等。

\8. 缓存优化：适当使用缓存（如Redis），可以显著减轻后端数据库的压力，提高系统的响应速度。

\9. CDN（内容分发网络）：对于静态资源，比如图片、CSS、JS等文件，可以使用CDN进行加速。

\10. 服务端渲染：对于前后端分离的项目，可以考虑使用服务端渲染，减少浏览器端的计算量，加快页面的首屏加载速度。

**2.** ***\*项目用的是什么模式，但进程还是多线程还是协程处理的。\****

协程的方式处理外部请求

**3.** ***\*内存池说一下\****

内存池内存池（Memory Pool）是一种内存管理技术，用于预先分配一块连续的内存空间，并在需要时将其分配给应用程序。内存池的主要目的是提高内存分配的性能、减少内存碎片以及简化内存管理。内存池的工作原理如下：

预分配：内存池在初始化时预先分配一块连续的内存空间。这个空间通常比应用程序实际需要的内存稍大，以便在需要时可以快速分配内存。

内存分配：当应用程序需要分配内存时，内存池会从预分配的内存空间中找到一个合适的区域，并将其分配给应用程序。这种分配方式通常比操作系统的默认内存分配方法更快，因为内存池可以更好地控制内存分配的策略和优化。

内存释放：当应用程序不再需要分配的内存时，它会将内存归还给内存池，而不是直接归还给操作系统。内存池会将归还的内存标记为空闲，以便在将来需要时重新分配。

优点：提高性能、减少内存碎片、简化内存管理：内存池可以简化内存管理，因为它将内存分配和释放的逻辑封装在内存池中，使得应用程序可以专注于业务逻辑。

**4.** ***\*有没有用过go的内存查看工具\****

在

**5.** ***\*布隆过滤器知道吗？（解决缓存穿透）\****

布隆过滤器的基本原理是，当一个元素被加入集合时，通过 K 个哈希函数将这个元素映射成位数组中的 K 个点，然后将这些点标记为 1。检索时，我们只需将待检索元素同样通过 K 个哈希函数映射到位数组，如果数组中的 K 个位置有任何一个为 0，则待检索元素一定不在集合中；如果 K 个位置全部为 1，则该元素可能在集合中。

优点：空间效率：由于布隆过滤器使用位数组来存储数据，因此比其他数据结构更节省空间。查询速度快：布隆过滤器的查询时间复杂度为 O(K)，K 为哈希函数的个数，与待查询的元素个数无关。

缺点：误判率：布隆过滤器存在一定的误判率，即可能会把不在集合中的元素误判为在集合中。这是因为不同的元素可能被哈希到位数组的同一位置。无法删除：在布隆过滤器中，一旦一个元素被加入，就无法被删除。因为删除某个元素可能会影响到其他元素。

**6.** ***\*R\*******\*edis的\*******\*三个模式各自试用的场景是什么\****

\1. 主从复制：适用场景：读取负载较重的应用，需要在多个从节点上分摊读取请求。

主从复制模式主要用于实现数据的备份和读取负载均衡。在这种模式下，一个主节点负责处理写入操作，同时将数据同步到一个或多个从节点。从节点可以处理读取操作，这样可以在多个从节点上分摊读取请求，提高系统的读取性能。然而，主从复制模式并不支持自动故障转移，如果主节点出现故障，需要手动切换到从节点。

\2. 哨兵模式：适用场景：需要自动故障转移和高可用性的应用。

哨兵模式是在主从复制的基础上，增加了自动故障转移的功能。在哨兵模式下，除了主节点和从节点之外，还有一个或多个哨兵节点。哨兵节点负责监控主节点和从节点的状态，当主节点出现故障时，哨兵节点会自动将一个从节点升级为主节点，并更新其他从节点的主节点信息。哨兵模式可以在主节点出现故障时，自动切换到从节点，提高系统的可用性。

\3. 集群模式：适用场景：需要数据分片和高扩展性的应用。

集群模式主要用于解决数据的分片和扩展性问题。在集群模式下，数据会被分片存储在多个节点上，每个节点只存储一部分数据。这样，当数据量增大时，可以通过增加节点的数量来扩展系统的容量。此外，集群模式还支持在节点间自动分片，以及当某个节点出现故障时，自动将其上的数据迁移到其他节点上，从而提供更高的可用性和扩展性。

总之，这三种模式可以根据实际需要进行组合使用。例如，可以使用主从复制或哨兵模式实现高可用性，同时使用集群模式实现数据分片和高扩展性。在实际应用中，需要根据系统的需求和性能要求，选择合适的模式。

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

***\*腾讯音乐&元象科技一面：\****

**1.** ***\*分布式锁se\*******\*tnx\*******\*在多进程情况下问题\****

在锁超时问题：当一个进程成功获取锁后，如果在执行任务时发生异常或者执行时间过长，可能导致锁没有被正确释放。这样，其他进程将无法获取锁，从而导致死锁。为了解决这个问题，可以为锁设置一个合适的超时时间，在超时后锁会自动释放。

锁非原子操作问题：SETNX命令和设置锁的超时时间是两个独立的操作，这可能导致在设置锁和设置超时时间之间发生故障，从而使锁没有正确设置超时时间。为了解决这个问题，可以使用SET命令的NX和EX选项将设置锁和设置超时时间合并为一个原子操作。

锁释放问题：当一个进程完成任务并尝试释放锁时，如果锁已经超时并被其他进程获取，那么释放锁的操作将会错误地释放了其他进程的锁。为了避免这个问题，可以在设置锁时为锁分配一个唯一的值（例如UUID），并在释放锁时检查锁的值是否与预期相符。

锁重入问题：在某些情况下，一个进程可能需要在已经获取锁的情况下再次获取锁。如果使用SETNX实现的分布式锁不支持重入，可能会导致死锁。为了解决这个问题，可以为每个进程维护一个计数器，用于记录当前进程获取锁的次数。当进程再次请求锁时，只需增加计数器即可。在释放锁时，将计数器减一，当计数器为零时才真正释放锁。

集群环境下的锁问题：在Redis集群环境下，使用SETNX实现的分布式锁可能会遇到数据一致性问题。例如，当一个进程在某个节点上成功获取锁后，其他节点可能还没有来得及同步锁的信息，导致其他进程也获取到了锁。为了解决这个问题，可以使用Redlock算法在多个Redis节点上实现分布式锁。

**2.** ***\*Z\*******\*card操作的时间复杂度是多少\****

有序集合是通过跳跃列表（Skip List）和哈希表（Hash Table）双重数据结构来存储的。哈希表用于存储元素及其分数，跳跃列表用于存储排序后的元素。

当执行ZCARD命令时，Redis只需要返回哈希表中元素的数量，这是一个常数时间操作，所以时间复杂度是O(1)。并不需要遍历整个有序集合或者跳跃列表，所以无论有序集合中元素的数量如何，ZCARD命令的执行时间都是恒定的。

**3.** ***\*不考虑并发性能，怎么用\*******\*mysql\*******\*实现商品扣减回滚不超限购\****

在商品表（products）：存储商品的基本信息，包括商品ID、等字段。

库存表（inventory）：存储商品的库存信息，包括商品ID、库存数量、已售数量等字段。

订单表（orders）：存储用户购买商品的订单信息，包括订单ID、、购买数量等字段。

如果在并发的情况下直接操作数据库，可能会出现超售的问题。这是因为在多线程或多进程环境下，多个线程或进程可能同时读取到相同的库存数量，然后都进行扣减库存的操作，最终导致实际售出的数量超过库存。可以采用以下几种方式：

悲观锁：在查询库存并扣减库存的操作中，使用数据库的行锁或表锁，确保同一时间只有一个线程或进程可以操作库存。这种方式可以有效防止超售，但会降低系统的并发性能。

乐观锁：在库存表中添加一个版本号字段，每次更新库存时检查版本号是否与之前读取的一致，如果一致则更新库存并增加版本号，否则重试。这种方式可以在一定程度上提高并发性能，但在高并发情况下可能会有较多的重试操作。

数据库事务：使用数据库事务来确保查询库存和扣减库存的操作是原子的。在事务中，首先查询库存，如果库存充足则扣减库存，否则回滚事务。这种方式可以防止超售，但在高并发情况下可能会导致数据库压力过大。

序列化隔离级别：将数据库的事务隔离级别设置为序列化（SERIALIZABLE），这是最高的隔离级别，可以防止并发事务导致的各种问题，包括超售。但这会降低并发性能，并可能导致更多的锁冲突。

**4.** ***\*U\*******\*pdate会有并发问题吗\****

UPDATE操作在并发环境下可能会出现并发问题。以下是一些可能导致并发问题的情况：

丢失更新（Lost Update）：当两个或多个事务同时修改同一条数据时，一个事务的修改可能会被另一个事务覆盖。例如，两个事务同时读取到某个账户的余额为1000元，然后分别将余额减少100元，最终余额可能被错误地更新为900元，而实际应该为800元。

脏读（Dirty Read）：当一个事务读取到另一个事务尚未提交的修改时，可能会出现脏读问题。例如，一个事务将某个商品的价格从100元更新为200元，但尚未提交；另一个事务读取到这个尚未提交的修改，可能会导致计算错误或其他问题。

不可重复读（Non-Repeatable Read）：当一个事务在同一时间范围内多次读取同一条数据，但每次读取的结果不同，可能会出现不可重复读问题。例如，一个事务读取某个商品的价格为100元，然后另一个事务将价格更新为200元，再次读取时价格变为200元。

幻读（Phantom Read）：当一个事务在同一时间范围内多次查询同一条件，但每次查询的结果集不同，可能会出现幻读问题。例如，一个事务查询所有价格低于100元的商品，然后另一个事务将某个商品的价格从200元更新为50元，再次查询时结果集发生变化。

**5.** ***\*雪花算法简单说下，什么时候雪花算法会出现uuid重复\****

原理：1位符号位，始终为0。

41位时间戳（毫秒级），表示从特定时间（例如1970年1月1日）开始到当前时间的毫秒数。41位的时间戳可以使用约69年。

10位机器标识，可以部署在1024个节点，包括5位数据中心ID和5位机器ID。

12位序列号，表示在同一毫秒内同一节点可以生成4096个ID。

重复的情况：

​	时钟回拨：如果服务器的系统时间被调整回到了之前的时间，可能会生成重复的ID。为了解决这个问题，雪花算法通常会拒绝在时钟回拨期间生成ID，或者使用逻辑时钟来确保时间的单调递增。

序列号溢出：如果在同一毫秒内同一节点生成的ID数量超过了4096，序列号会溢出，可能会生成重复的ID。为了解决这个问题，雪花算法通常会在序列号溢出时等待到下一毫秒再生成ID。

机器标识重复：如果两个节点的数据中心ID和机器ID都相同，会生成重复的ID。为了解决这个问题，需要确保每个节点的数据中心ID和机器ID的唯一性。

**6.** ***\*抛kaf\*******\*ka\*******\*失败的情况怎么处理，失败就回退吗，如果只是网络延时导致的失败呢\****

重试：在很多情况下，发送失败可能是由于网络延迟、短暂的服务不可用等暂时性问题引起的。在这种情况下，可以设置生产者客户端的重试次数和重试间隔，让生产者在发送失败时自动进行重试。

回退：如果重试仍然失败，可以选择回退操作。具体的回退策略取决于业务需求和场景。例如，可以将发送失败的消息存储在本地磁盘或数据库中，稍后进行重发；或者通知相关人员进行人工干预。

错误处理：对于发送失败的消息，可以将其发送到一个专门的错误处理队列或系统中，进行单独处理。这样可以确保正常消息的处理不受影响，同时可以对错误消息进行分析、重发或其他处理。

监控和报警：对于发送失败的情况，可以通过监控和报警系统来实时了解系统的健康状况。当检测到发送失败时，可以立即触发报警，通知相关人员进行处理。

容错和降级：在某些情况下，可以允许部分消息发送失败，以保证系统的整体可用性。例如，在高并发场景下，可以通过限流、降级等手段来减少对Kafka的依赖，确保关键业务的正常运行。

**7.** ***\*怎么保证订单号的唯一性，一点重复的概率都没有\****

在

**8.** ***\*考虑到网络并发的问题，网络延迟等，可能有两个同样时间的同一用户下单时间请求，对于订单表，同一个商品的多次购买，怎么保证插入的语句不会重复呢\****

唯一订单号、幂等操作、事务控制

**9.** ***\*主键需要具备哪些特性\****

唯一性、非空性、不变形、只能有一个主键、主键列有主键索引、

**10.** ***\*为什么用自增id不用\*******\*uuid\*******\*保证唯一\****

在字符串作为主键和自增ID作为主键各有优缺点，具体取决于实际应用场景和需求。下面列出了两者之间的主要区别：

写多的场景：

页分裂减少：使用自增主键的话，在多个插入动作的时候，底层B+树直接追加就可以了，对树的结构的变化不大，其实实际上这个订单号和主键自增id都不会用到实际效果，但是使用id可以在多写的场景下，页表是一个有序的递增效果，不会出现说分页操作，能够让IO的命中率更高。而如果用字符串做主键的话，就会出现随机插入，频繁的出现分页动作。在存储数据时，通常将数据分成多个页（Page）。使用较小的数据类型可以减少页分裂的可能性，因为更多的数据可以放入每个页中。页分裂会导致性能下降，因为数据库需要额外的操作来维护数据的物理存储。

存储空间和性能：

字符串主键通常占用更多的存储空间，尤其是在关系表和索引中。相比之下，自增ID主键通常是整数类型，占用的空间较小。字符串主键在查询和排序时可能会比整数主键慢，因为字符串比较操作相对较慢。

可读性和可预测性：

字符串主键可能具有更高的可读性，例如使用UUID或业务相关的字符串作为主键。这在某些情况下可能有助于调试和数据管理。自增ID主键具有连续性和可预测性，可能会导致安全和隐私问题。例如，攻击者可以通过遍历自增ID来获取数据。相比之下，UUID等随机字符串主键具有更高的安全性。

分布式环境：

字符串主键，如UUID，可以在分布式环境中生成全局唯一的ID，无需额外的同步和协调机制。自增ID主键在分布式环境中可能需要额外的处理，例如使用分布式ID生成服务（如雪花算法）或者为每个节点分配不同的ID范围。

外键关联：

字符串主键在关联表中可能更容易理解，尤其是在业务相关的字符串主键情况下。自增ID主键在关联表中可能需要额外的查询来获取相关联的实体信息，但由于整数比较操作较快，关联查询的性能可能会更好。

总的来说，没有绝对的好坏之分，选择字符串主键还是自增ID主键取决于具体的业务需求和系统环境。在考虑主键选择时，需要权衡存储空间、性能、可读性、可预测性、分布式环境和外键关联等因素。

**11.** ***\*c\*******\*ount\*******\*(\*)count(1)count(\*******\*主键)count\*******\*(\*******\*二级索引)count\*******\*(\*******\*字段)五个的性能排序\****

count(*)=count(1)>count(二级索引)>count(主键)>count(字段)

count(*)会被server转化成count(0)

在count(1)、 count(*)、 count(主键字段)在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。

所以，如果要执行 count(1)、 count(*)、 count(主键字段) 时，尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。

再来，就是不要使用 count(字段) 来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计。如果你非要统计表中该字段不为 NULL 的记录个数，建议给这个字段建立一个二级索引。

**12.** ***\*redis的主从复制介绍下\****

[https://xiaolincoding.com/redis/cluster/master_slave_replication.html#%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%90%8C%E6%AD%A5](#第一次同步)

**13.** ***\*算法题：\*******\*有一个长度为m-1的数组，数组元素都是正数，元素无序并且不存在重复数字，元素为1到m但是缺失了一个数，\*******\*找出这个正数值。如m\*******\*=4,[1,4,3],\*******\*缺失2\****

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps6.jpg) ![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps7.jpg)

 

***\*讯雷科技一面：\****

**1.** ***\*单例模式中，全局变量和饿汉模式的区别\****

单例模式是一种设计模式，用于确保一个类只有一个实例，并提供一个全局访问点。全局变量和饿汉模式是实现单例模式的两种方法，它们之间有一些区别：

a. 初始化方式：

全局变量：全局变量在程序启动时就会被自动创建和初始化。它们在整个程序运行期间都存在，直到程序结束。

饿汉模式：饿汉模式是在类加载时就创建和初始化单例对象。这种方式下，单例对象在类加载时就已经创建好了，当需要使用时直接返回即可。由于饿汉模式在类加载时就初始化了实例，因此不存在多线程同步问题。

b. 线程安全：

全局变量：全局变量本身是线程安全的，因为它们在程序启动时就已经创建和初始化。但是，当多个线程访问和修改全局变量时，可能会导致不可预期的结果和数据不一致。

饿汉模式：饿汉模式是线程安全的，因为它在类加载时就创建和初始化了单例对象。这样可以确保在多线程环境下，只有一个实例存在。

c. 延迟加载：

全局变量：全局变量在程序启动时就会被创建和初始化，因此不存在延迟加载。

饿汉模式：饿汉模式在类加载时就创建了单例对象，因此也不存在延迟加载。这意味着，即使单例对象在程序运行过程中从未被使用，它也会被创建和占用内存。

d. 内存占用：

全局变量：全局变量在程序启动时就会被创建和初始化，因此会占用内存。如果有很多全局变量，可能会导致内存占用过大。

饿汉模式：饿汉模式在类加载时就创建了单例对象，因此会占用内存。但是，由于只有一个实例，所以内存占用相对较小。

总结：全局变量和饿汉模式都可以实现单例模式，但它们在初始化方式、线程安全、延迟加载和内存占用方面有所不同。饿汉模式相对于全局变量来说，具有更好的线程安全性。然而，饿汉模式不支持延迟加载，可能会导致资源浪费。

**2.** ***\*hashmap读和写时间复杂度\*******\*、是不是线程安全的\****

Go 语言中的哈希映射（hashmap）是通过内置的 map 类型实现的。map 类型的读和写操作的平均时间复杂度都是 O(1)，不是线程安全的。

**3.** ***\*你说写会加锁、如果把那把锁拿掉呢\*******\*。这里没有锁只是一个写标志位。\****

不会加锁，在查找、赋值、遍历、删除的过程中都会检测写标志，一旦发现写标志置位（等于1），则直接 panic。赋值和删除函数在检测完写标志是复位之后，先将写标志位置位，才会进行之后的操作。

**4.** ***\*数组和链表的区别\****

空间存储方式、访问速度、内存分配、插入删除销量

**5.** ***\*压测时候的指标、带宽写满了没、文件描述符、半连接全连接队列\****

以下是可能的性能瓶颈以及如何提高接口 QPS（每秒请求量）的一些建议：

CPU：JSON 编解码、Redis 操作和 Kafka 操作等可能会消耗 CPU 资源。如果 CPU 使用率非常高，可能会导致性能瓶颈。优化 JSON 编解码逻辑，例如使用更高效的 JSON 库，或者减少不必要的编解码操作，可以帮助减少 CPU 的使用。

内存：JSON 编解码、Redis 操作和 Kafka 操作等可能会产生一定的内存消耗。如果内存使用量过高，可能会导致性能瓶颈。优化内存使用，例如复用对象，避免不必要的内存分配，可以帮助减少内存的使用。

网络带宽：与 Redis 和 Kafka 的通信可能会消耗网络带宽。如果网络带宽使用过高，可能会导致性能瓶颈。优化网络通信，例如减少不必要的网络请求，使用压缩等，可以帮助减少网络带宽的使用。

磁盘 I/O：虽然你的接口可能不直接进行磁盘操作，但 Redis 和 Kafka 可能会进行磁盘 I/O，特别是当它们的内存不足时。如果磁盘 I/O 过高，可能会导致性能瓶颈。优化 Redis 和 Kafka 的配置，例如增加它们的内存，可以帮助减少磁盘 I/O。

第三方组件：Redis 和 Kafka 的性能也会影响你的接口的性能。如果它们的性能不足，可能会导致性能瓶颈。优化 Redis 和 Kafka 的使用，例如使用 pipeline 来批量操作，使用适当的数据结构和索引，可以帮助提高它们的性能。

文件描述符：每个 TCP 连接都需要一个文件描述符。如果你的接口需要处理大量的并发连接，可能会耗尽文件描述符，从而导致性能瓶颈。优化连接管理，例如复用连接，及时关闭不再使用的连接，可以帮助减少文件描述符的使用。

总的来说，要提高接口的 QPS，你需要从多个方面进行优化：优化代码逻辑以减少 CPU 和内存的使用，优化网络通信以减少网络带宽的使用，优化 Redis 和 Kafka 的使用以提高它们的性能，优化连接管理以减少文件描述符的使用。同时，你也需要使用性能监控工具来监控这些资源的使用情况，以便发现并解决性能瓶颈。

**6.** ***\*go的package和go module\*******\*怎么理解\****

Go package（包）：包是 Go 代码的基本组织单位。一个包由一个目录下的一个或多个 .go 文件组成，这些文件共享相同的包名。包名通常与其目录名相同，但也可以不同。包的目的是将相关的代码逻辑组织在一起，以便在其他地方重用和共享。在 Go 代码中，你可以通过导入包来使用其公开的类型、变量、常量和函数。包的导入路径是从项目的 GOPATH 或 GOROOT 开始的相对路径

Go module（模块）：

Go module 是 Go 1.11 引入的一种新的依赖管理方式。模块是一组相关的 Go 包，它们被版本控制并作为一个整体进行管理。模块使你能够明确地声明项目的依赖关系，包括所需的版本，从而确保项目的可重复构建和更好的依赖隔离。

在使用 Go module 时，你需要在项目根目录下创建一个 go.mod 文件。该文件列出了项目的模块路径（通常与仓库路径相同）和依赖关系。当你构建或运行项目时，Go 工具链会自动下载并安装所需的依赖版本。依赖项将存储在项目外部的模块缓存中，而不是像 GOPATH 那样存储在项目内部。

总结：

Go package 是代码的基本组织单位，用于将相关的代码逻辑组织在一起。

Go module 是一种依赖管理方式，用于声明项目的依赖关系和版本控制。

在实际项目中，你可能需要使用包来组织代码，并使用模块来管理依赖关系，以确保项目的可维护性和可重复构建。

**7.** ***\*最难的一个项目\*******\*（\*******\*这个系统整理下\*******\*，达到能够连贯说出来）\****

**8.** ***\*工作中tcp抓过包没\*******\*（\*******\*抓包的话关注哪些\*******\*）\****

**9.** ***\*工作中在\*******\*在\*******\*学习哪些知识\****

 

 

***\*虾皮一面：\****

**1.** ***\*Tcp\*******\*四次挥手中处于c\*******\*lose_wait\*******\*状态是哪个阶段\****

被动关闭的一段收到第一个Fin回复Ack后

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps8.jpg) ![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps9.jpg)

**2.** ***\*T\*******\*cp的短链接长链接是什么意思\****

它们主要的区别在于连接建立后是否立即断开。

短连接：在短连接中，客户端和服务器每进行一次数据交互操作，就建立一个新的连接，数据发送完毕后立即断开连接。这种方式的优点是管理起来相对简单，服务器处理完客户端的请求，并接收到客户端的应答后，即断开连接。

长连接：在长连接中，客户端和服务器建立连接后，就保持连接状态，可以进行多次数据交互操作，直到连接被显式地断开。长连接适用于需要频繁交互的场景，可以减少因为建立和断开连接而产生的额外开销。

**3.** ***\*T\*******\*cp长链接隔了很长一段时间再进行交互，怎么保证这个链接还是有效的\****

TCP Keepalive 机制：TCP 提供了 Keepalive 机制，用于在连接空闲时定期发送探测数据包。如果在指定时间内未收到对方的响应，则认为连接已断开。通过启用 Keepalive 机制，可以在连接空闲时检测连接的有效性。Keepalive 机制的参数（如探测间隔和重试次数）可以根据需要进行调整。

应用层心跳机制：在应用层实现心跳机制，即在连接空闲时定期发送应用层的心跳数据包。接收方在收到心跳数据包后，需要回应一个心跳响应包。如果在指定时间内未收到对方的心跳响应，则认为连接已断开。应用层心跳机制的优点是可以根据应用的需求进行定制，同时可以检测应用层的可用性。

适当调整超时时间：根据应用需求，可以适当调整 TCP 连接的超时时间。这可以确保在长时间不活跃的情况下，连接仍然保持有效。但请注意，过长的超时时间可能导致资源浪费，因此需要权衡超时时间和资源使用之间的关系。

总之，在使用 TCP 长连接时，可以通过启用 Keepalive 机制、实现应用层心跳机制、调整超时时间来保持连接的有效性。

**4.** ***\*在 TCP 长连接的情况下，多个请求到来时，TCP 通过以下机制确保消息的正确接收\****

在 TCP 长连接的情况下，多个请求到来时，TCP 通过以下机制确保消息的正确接收：

序列号：TCP 协议为每个数据包分配一个唯一的序列号。序列号用于标识数据包在整个数据流中的位置，确保接收方可以按照正确的顺序接收和重组数据包。

确认应答：当接收方收到数据包后，会发送一个确认应答（ACK）给发送方。确认应答包含一个确认号，表示接收方期望收到的下一个数据包的序列号。发送方根据确认应答来判断数据包是否已被成功接收。

重传机制：如果发送方在一定时间内没有收到接收方的确认应答，会认为数据包丢失，然后重新发送数据包。这样可以确保数据包在网络不稳定的情况下仍然可以被正确接收。

流量控制：TCP 协议使用滑动窗口机制来实现流量控制。滑动窗口表示发送方可以发送的数据量，由接收方的可用缓冲区大小决定。发送方根据滑动窗口的大小来调整发送速率，确保接收方不会被大量数据淹没。

拥塞控制：TCP 协议还实现了拥塞控制机制，用于避免网络拥塞。当发送方检测到网络拥塞时（例如，连续丢失数据包），会降低发送速率，直到网络恢复正常。

应用层协议：在 TCP 的基础上，应用层协议（如 HTTP、FTP 等）可以定义自己的消息格式和边界。例如，HTTP 协议使用内容长度（Content-Length）或分块传输编码来标识消息的边界。这样可以确保接收方可以正确地解析和处理多个请求。

**5.** ***\*T\*******\*cp的保活具体实现知道吗\****

TCP 的保活（Keepalive）机制是一种用于检测和管理空闲连接的方法。当 TCP 连接在一段时间内没有任何数据传输时，TCP 保活机制会定期发送探测数据包以检查连接是否仍然有效。以下是 TCP 保活机制的具体实现：

启动保活机制：在创建 TCP 连接时，可以选择是否启用保活机制。这通常通过设置 socket 选项 SO_KEEPALIVE 来实现。请注意，保活机制默认是关闭的，需要显式地启用。

发送探测数据包：当 TCP 连接在一段时间（通常为 2 小时）内没有任何数据传输，保活机制会开始发送探测数据包。探测数据包是一个特殊的 TCP 数据包，它的序列号为当前序列号减 1，不包含任何数据，只包含一个 ACK 标志。

等待响应：发送探测数据包后，保活机制会等待对方的响应。如果在一段时间（通常为 75 秒）内收到对方的 ACK 数据包，则认为连接仍然有效，然后继续等待下一次的探测。如果在这段时间内没有收到对方的 ACK 数据包，则重复发送探测数据包。

断开连接：如果连续发送一定次数（通常为 9 次）的探测数据包后仍然没有收到对方的 ACK 数据包，则认为连接已断开，然后关闭连接并通知应用程序。

TCP 保活机制并不能保证连接的可靠性，它只是一种检测和管理空闲连接的方法。在某些情况下，例如网络中断或对方崩溃等，保活机制可能无法及时检测到连接的断开。因此，应用程序还需要实现自己的超时和重试机制以确保连接的可靠性。

**6.** ***\*怎么处理黑产用户的海量并发请求锁住订单\****

**7.** ***\*M\*******\*ysql的事务是有哪几种事务\****

读未提交、读已提交、可重复读、串行话

**8.** ***\*幻读是通过什么方式来解决的\****

针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读。

针对当前读（select ... for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读。

MySQL 可重复读隔离级别并没有彻底解决幻读，只是很大程度上避免了幻读现象的发生。要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。

**9.** ***\*缓存和数据库的不一致怎么处理的，除了先更新数据库再删缓存还有什么方式。\****

如果我们的业务对缓存命中率有很高的要求，我们可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况。数据不一致两种做法：

在更新缓存前先加个分布式锁，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。

在更新完缓存时，给缓存加上较短的过期时间，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。

对了，针对「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「延迟双删」。

**10.** ***\*针对mysql的慢查询怎么定位处理\****

**11.** ***\*CAP\*******\*理论具体是什么，说一个你知道的具体产品介绍它满足CAP的什么\****

一致性（Consistency）：一致性是指分布式系统中所有节点在同一时刻看到的数据是一致的。换句话说，当一个节点更新了数据后，其他节点能立即看到更新后的数据。一致性是分布式系统中最直观的需求，但在实际应用中，为了提高性能和可用性，可能需要在一定程度上牺牲一致性。

可用性（Availability）：可用性是指分布式系统在任何时刻都能对外提供服务。无论发生了硬件故障、网络问题还是其他异常情况，分布式系统都能继续提供服务。为了实现高可用性，分布式系统通常采用冗余、负载均衡等技术。

分区容忍性（Partition Tolerance）：分区容忍性是指分布式系统在遇到网络分区（即节点之间的通信中断）时，仍能继续提供服务。在分布式系统中，网络分区是不可避免的，因此分区容忍性是分布式系统必须具备的特性。

Redis 集群模式设计的目标是在保证分区容忍性（Partition Tolerance）的前提下，尽可能地保证一致性（Consistency）。因此，Redis 集群模式满足 CAP 理论中的 CP。

分区容忍性（Partition Tolerance）：Redis 集群通过分片（sharding）技术将数据分布在多个节点上，每个节点负责一部分数据，从而实现数据的分区。当某个节点发生故障时，集群仍然可以继续提供服务。

一致性（Consistency）：Redis 集群通过主从复制和故障转移机制尽可能地保证一致性。当主节点发生故障时，集群会自动选举一个从节点作为新的主节点，以保证数据的可用性和一致性。但请注意，Redis 集群的一致性是最终一致性，而不是强一致性。在主节点发生故障和故障转移期间，可能会出现短暂的数据不一致。

可用性（Availability）：虽然 Redis 集群在设计上重视一致性，但在某些情况下，为了保证一致性，可能会牺牲可用性。例如，当集群中的大多数主节点或者某个主节点的所有从节点都发生故障时，集群会进入下线状态，无法提供服务，直到故障恢复。

总的来说，Redis 集群模式满足 CAP 理论中的 CP，即在保证分区容忍性的前提下，尽可能地保证一致性。

Apache ZooKeeper：ZooKeeper 是一个分布式协调服务，用于管理分布式应用程序的配置信息、命名空间和分布式同步等。ZooKeeper 主要满足一致性（Consistency）和分区容忍性（Partition Tolerance），即 CP 模型。ZooKeeper 通过原子广播协议（如 Zab）来实现强一致性，确保在发生网络分区时，仍然可以提供一致的服务。

Apache Cassandra：Cassandra 是一个高可扩展、高性能的分布式 NoSQL 数据库。Cassandra 主要满足可用性（Availability）和分区容忍性（Partition Tolerance），即 AP 模型。Cassandra 通过一种称为最终一致性（Eventual Consistency）的模型来平衡一致性和可用性，允许在一定程度上的数据不一致，以换取更高的可用性。

**12.** ***\*订单支付场景下的因为网络等原因重复请求应该怎么保证支付扣款的幂等性\****

唯一支付 ID：为每笔支付分配一个唯一的支付 ID，例如使用 UUID 或订单号加上时间戳等方式生成。在处理支付请求时，首先检查支付 ID 是否已经存在。如果已经存在，则返回之前的支付结果，而不是重新处理支付。这样可以确保即使收到重复的支付请求，也不会导致多次扣款。

分布式锁：在处理支付请求时，使用分布式锁（如 Redis、ZooKeeper 等）来锁定订单。这样可以确保同一时刻只有一个请求能够处理订单，避免因为并发导致的重复扣款。请注意，分布式锁需要设置合适的超时时间，以防止死锁。

状态检查：在处理支付请求之前，首先检查订单的状态。如果订单已经处于支付成功或支付失败的状态，则拒绝当前请求，避免重复扣款。同时，确保订单状态的更新操作是原子性的，避免并发问题。

幂等框架：使用幂等框架（如 Idempotent Framework）来处理支付请求。幂等框架可以自动处理重复请求的检测和处理，确保支付操作具有幂等性。

应用层重试策略：客户端在发起支付请求时，可以实现一定的重试策略，例如使用指数退避算法。这样可以在网络不稳定的情况下，降低重复请求的可能性。

**13.** ***\*浏览器的重试机制带来的重复请求如何避免\****	

使用幂等 HTTP 方法：在设计 API 时，尽量使用幂等的 HTTP 方法，例如 GET、PUT、DELETE 等。这些方法在重复请求时不会导致服务器端的状态发生改变。避免使用非幂等的方法，如 POST，因为重复的 POST 请求可能会导致服务器端创建多个资源。

使用 POST/Redirect/GET（PRG）模式：在处理表单提交等场景时，可以采用 PRG 模式。当用户提交表单后，服务器处理 POST 请求并进行相应的操作，然后返回一个 302 重定向到 GET 请求。这样，浏览器会执行 GET 请求来获取结果页面，而不是重复 POST 请求。即使用户刷新页面，也只会重新执行 GET 请求，而不会导致重复的 POST 请求。

添加请求 Token：在生成表单时，为每个表单分配一个唯一的 Token，并将 Token 作为隐藏字段存储在表单中。当用户提交表单时，服务器会检查 Token 是否有效。如果 Token 有效，则处理请求并将 Token 标记为无效；如果 Token 无效，则拒绝请求。这样可以防止用户重复提交表单。

**14.** ***\*算法题：排序链表，nlo\*******\*g(n)\*******\*时间复杂度和\*******\*O(1)\*******\*的空间复杂度\****

归并排序，注意找中间节点的方法

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps10.jpg)![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps11.jpg) 

 

***\*字节抖音游戏一面：\****

**1.** ***\*kafka如果在下游有一条消息写入数据库失败，怎么让上游感知到这条失败，然后上游不再继续传递相关的消息了\****

a) 在使用消费者组的错误处理策略。当消费者遇到错误时，可以选择停止消费，或者将错误信息发送回上游。这样，上游可以根据错误信息决定是否继续发送消息。具体实现方法如下：

· 在消费者代码中，当写入数据库失败时，捕获异常并处理错误。

· 在处理错误的代码中，可以选择停止消费者，或者将错误信息发送回上游。

· 上游根据接收到的错误信息决定是否继续发送消息。

b) 使用Kafka Streams处理错误。Kafka Streams是一个流处理框架，可以在Kafka中处理数据流。如果在Kafka Streams中处理数据时遇到错误，可以选择停止处理或者将错误信息发送回上游。具体实现方法如下：

· 使用Kafka Streams创建一个处理数据流的应用程序。

· 在应用程序中，当写入数据库失败时，捕获异常并处理错误。

· 在处理错误的代码中，可以选择停止处理，或者将错误信息发送回上游。

· 上游根据接收到的错误信息决定是否继续发送消息。

c) 使用事务支持。Kafka 0.11.0.0及更高版本支持事务，可以确保生产者和消费者之间的一致性。具体实现方法如下：

· 在生产者端启用事务支持，并为生产者分配一个事务ID。

· 在消费者端启用事务支持，并设置消费者的***\*isolation.level\****为***\*read_committed\****。

· 当消费者遇到错误时，使用生产者的事务ID进行终止事务操作。这将导致事务回滚，从而确保上游不再继续传递相关的消息。

请注意，这些方法可能会影响系统的性能和吞吐量。在实际应用中，请根据具体需求和场景选择合适的方法。

**2.** ***\*网页地址短链接转换原理\****

网页短链接服务通过将长网址映射到较短的URL，使得用户可以更方便地分享和传播链接。短链接转换的原理主要包括以下几个步骤：

a) 生成唯一标识符：当用户提交一个长网址时，短链接服务会为其生成一个唯一的标识符。这个标识符可以是一个递增的整数、随机字符串或哈希值。例如，可以使用长网址的MD5哈希值作为标识符，或者使用数据库中的自增ID。

b) 编码标识符：将唯一标识符编码为一个较短的字符串。常用的编码方法包括Base62（使用0-9、a-z、A-Z共62个字符）和Base64（使用0-9、a-z、A-Z、+、/共64个字符）。将标识符编码为较短的字符串可以减少URL的长度，使其更容易分享和传播。

c) 构建短链接：将编码后的字符串与短链接服务的域名拼接，形成一个完整的短链接。例如，如果短链接服务的域名为***\*example.com\****，编码后的字符串为***\*abc123\****，那么短链接为***\*http://example.com/abc123\****。

d) 存储映射关系：将长网址与短链接（或编码后的字符串）之间的映射关系存储在数据库中。这样，当用户访问短链接时，短链接服务可以根据映射关系找到对应的长网址，并将用户重定向到长网址。

e) 过期判断处理：短链接服务通常会在生成短链接时设定一个过期时间，例如24小时、7天或30天等。将这个过期时间存储在数据库中，每次用户访问短链接时，短链接服务会先检查当前时间是否超过过期时间。如果超过过期时间，那么短链接就失效，服务可以返回一个错误信息或者重定向到一个错误页面。如果没有超过过期时间，那么服务会正常重定向到长网址。另外，为了保持数据库的整洁，可以定期清理已经过期的短链接。

f) 数据库唯一性：为了保证数据库的唯一性，可以使用数据库的唯一索引或主键

g) 重定向访问：当用户访问短链接时，短链接服务会查询数据库，找到对应的长网址，然后通过HTTP 301或302重定向将用户引导到长网址。这样，用户可以通过短链接访问原始的长网址。

通过以上步骤，短链接服务可以将长网址转换为较短的URL，同时保持长网址和短链接之间的一一对应关系。这种转换原理使得短链接在分享和传播时更加方便，同时也可以节省存储和传输资源。

**3.** ***\*算法题：组合总和\*******\*[1,2,3,7]\*******\*输出\*******\*[[2,2,3],[7]]\****

 

**4.** ***\*设计一个高并发高性能的前后端系统，可以从哪些角度来考虑支持到高并发\****

静态资源cdn加载、连接池、长链接、链接复用别忘了

**5.** ***\*分布式锁可重入是什么意思\****

是指在分布式环境下的一种锁机制，它允许同一个线程或进程多次获取同一个锁，而不会导致死锁。分布式锁可重入的主要作用是简化分布式系统中的同步逻辑，避免死锁等问题。

在单机环境中，可重入锁（Reentrant Lock）是一种常见的锁机制，它允许同一个线程在已经获取锁的情况下，再次获取同一个锁，而不会产生死锁。可重入锁通过为每个锁关联一个计数器和一个拥有者线程来实现。当一个线程获取锁时，计数器加1，拥有者线程设置为当前线程；当线程释放锁时，计数器减1。当计数器为0时，锁被释放。这样，同一个线程可以多次获取同一个锁，而不会导致死锁。

***\*6．\****	***\*10亿个手机号去重，存在重复的就不要\****

在如果你想要使用位图的方式去重，并且只保留那些只出现一次的手机号码，你可以使用两个位图进行操作。

手机号码是11位的，且前三位是已知的运营商前缀，所以实际上手机号码的有效数字是8位，即最多有1亿个（10的8次方）。

对于一个只有1G内存的机器，1G=1024M，1M=1024K，1K=1024Byte，1Byte=8bit，所以1G大约等于85亿bit，足够存储1亿个号码的位图。

下面是具体的步骤：

创建两个位图，分别命名为bitmap1和bitmap2，每个位图大小为1亿bit。

读取手机号码，对于每一个手机号码，做以下操作：

如果bitmap1对应位置为0，将bitmap1对应位置设为1。

如果bitmap1对应位置为1，将bitmap2对应位置设为1。

扫描bitmap1和bitmap2，对于每一个位置，做以下操作：

如果bitmap1对应位置为1且bitmap2对应位置为0，说明这个手机号码只出现过一次。

如果bitmap1对应位置为0或者bitmap2对应位置为1，说明这个手机号码没有出现过或者出现过多次。

这样，你就可以得到所有只出现一次的手机号码。这种方法的时间复杂度为O(n)，空间复杂度为O(1)，非常高效。

 

***\*客路旅行一面：\****

**1.** ***\*G\*******\*o语言中初始化一个ctx的方法有哪些\****

可以使用context包中的context.Background()或context.TODO()函数来初始化一个空的Context。你也可以使用context.WithCancel(parent Context)，context.WithDeadline(parent Context, d time.Time)，context.WithTimeout(parent Context, timeout time.Duration)，context.WithValue(parent Context, key, val interface{})等函数来创建带有取消、超时、值等特性的Context。

**2.** ***\*用ctx存一个get\*******\*/\*******\*post请求的所有key\*******\*-value\*******\*参数，会有什么问题吗\****

Context主要用于传递跨API边界的请求范围的元数据，如取消信号、超时时间、认证令牌等。将HTTP请求的所有参数存储在Context中并不推荐，因为这可能使得Context过于臃肿，而且Context的设计初衷并不是用来传递大量的请求参数。

内存占用：大量的数据存储在Context中会占用更多的内存，特别是在并发量大的情况下，可能会导致内存迅速膨胀，甚至引发内存溢出。

性能影响：Context中的数据在goroutine之间传递时，会涉及到复制（go都是值复制的方式）和引用计数等操作，如果数据量大，会增加CPU的负载，降低程序的运行效率。

设计理念：Context的设计初衷是用来传递与请求相关的元数据，而不是用来作为在goroutine之间共享大量数据的工具。滥用Context可能会导致程序的设计变得混乱，不易于维护。

**3.** ***\*C\*******\*hannle的底层实现有哪些，它是并发安全的吗，怎么实现的并发安全\****

在Go语言的Channel实现了并发安全，主要是通过使用锁和同步原语来实现的。Channel内部使用了一些数据结构，如环形队列，以及同步原语如互斥锁（mutex）和条件变量来确保并发安全。

**4.** ***\*哪些变量在栈上创建，哪些在堆上创建，一个进程的栈最大是多大\****

\1. 栈上创建的变量：

· 局部变量（在函数内部定义的变量）

· 未发生内存逃逸的函数参数

\2. 堆上创建的变量：

· 全局变量（在函数外部定义的变量）

· 手动分配的空间（通过***\*new\****或***\*make\****分配的空间）

· 发生内存逃逸的变量（在函数内部创建，但在函数外部被引用的变量）

Go语言中，变量在栈上还是堆上创建取决于它的生命周期。如果编译器能确定变量的生命周期，那么它可能会在栈上创建；否则，它会在堆上创建。一个Goroutine的栈的大小是动态的，初始大小为2KB，最大可以达到1GB。

**5.** ***\*进程间通信、线程间通信，进程中的线程怎么和创建它的这个进程通信\****

进程间通信可以使用管道、信号、消息队列、共享内存、套接字等方式。线程间通信可以使用锁、条件变量、信号量、信号、消息队列等方式。线程和创建它的进程共享同一地址空间，因此它们可以直接读写同一内存。

线程和创建它的进程共享同一地址空间，它们可以通过共享变量、信号量、条件变量等同步原语进行通信

**6.** ***\*select\**** ***\** from table where id = a or id = b,\*******\*这种情况会怎么命中索引\****

如果id列有索引，那么MySQL可以使用索引合并（index merge）优化器来执行查询。它会分别查找id = a和id = b的结果，然后将结果合并。

**7.** ***\*mysql\*******\*的四大特性ACID\****

原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）

**8.** ***\*mysql\*******\*怎么保证一致性的、怎么保证原子性\****

· 持久性是通过 redo log （重做日志）来保证的；

· 原子性是通过 undo log（回滚日志） 来保证的；

· 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；

· 一致性则是通过持久性+原子性+隔离性来保证；

**9.** ***\*两阶段提交，什么时候写redolog什么时候写\*******\*binlog\****

在两阶段提交中，MySQL会preper阶段先写redo log，然后commit阶段写binlog。redo log是物理日志，记录的是数据页的物理修改，用于崩溃恢复。binlog是逻辑日志，记录的是SQL语句的逻辑修改，用于主从复制。

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps12.jpg) 

**10.** ***\*M\*******\*ysql什么情况下select会进行表锁\****

当你执行SELECT * FROM table WHERE name="123"这样的查询时，如果name不是索引，那么MySQL会进行全表扫描。但这并不意味着它会使用表锁。在InnoDB存储引擎中，全表扫描仍然会使用行锁，对每一行进行锁定和解锁。

然而，如果你在查询中使用了LOCK IN SHARE MODE或FOR UPDATE语句，那么InnoDB可能会使用表锁。因为在这种情况下，对全表的每一行加行锁可能会导致性能问题，所以InnoDB会选择使用表锁。

​	总的来说，InnoDB存储引擎在大多数情况下会优先使用行锁。只有在特定情况下，如显式请求表锁，或者执行大量的更新操作，才会使用表锁。

**11.** ***\*M\*******\*ysql 慢查询怎么分析优化\****

在a. 开启慢查询日志：在MySQL中，你可以开启慢查询日志来记录执行时间超过指定阈值的查询。通过配置***\*slow_query_log\****和***\*long_query_time\****参数，你可以控制慢查询日志的开启和阈值。

b. 分析慢查询日志：分析慢查询日志，找出执行时间较长的查询。你可以使用工具（如mysqldumpslow或pt-query-digest）来分析日志，找出出现频率高和执行时间长的慢查询。

c. 优化查询：针对慢查询，你可以采取以下方法进行优化：

\- 优化SQL语句：检查慢查询的SQL语句，看是否可以通过改写SQL、减少子查询、使用连接（JOIN）代替子查询等方法来优化。

\- 使用索引：检查慢查询是否使用了合适的索引。你可以使用`EXPLAIN`命令来查看查询的执行计划，找出没有使用索引或使用了低效索引的地方。然后，根据需要创建或修改索引。

\- 调整配置参数：根据慢查询的特点，调整MySQL的配置参数，如缓冲区大小、锁超时时间等，以提高查询性能。

\- 分区表：对于大表，可以考虑使用分区表来提高查询性能。通过将表分成多个独立的分区，可以减少查询时需要扫描的数据量。

d. 监控和调整：在进行优化后，继续监控慢查询日志，观察优化效果。根据实际情况，持续调整和优化慢查询。

通过以上步骤，可以分析和优化MySQL中的慢查询，提高数据库的性能。

**12.** ***\*慢查询explain分析，主要关注的字段是哪几个\****

在MySQL中，使用***\*EXPLAIN\****分析慢查询时，主要关注以下几个字段，以便了解查询的性能瓶颈并进行优化：

**1.** ***\*type\****：访问类型，表示MySQL如何访问表中的数据。通常，我们希望***\*type\****尽可能地靠前，以获得更好的性能。从最优到最差的顺序依次是：***\*system\**** > ***\*const\**** > ***\*eq_ref\**** > ***\*ref\**** > ***\*range\**** > ***\*index\**** > ***\*ALL\****。

**2.** ***\*possible_keys\****：可能使用的索引。这个字段列出了MySQL优化器认为可能使用的索引。如果这个字段为空，你可能需要考虑为表添加合适的索引以提高查询性能。

**3.** ***\*key\****：实际使用的索引。这个字段显示了MySQL优化器实际选择使用的索引。如果这个字段为空或与***\*possible_keys\****中索引不同，可能要调整索引或查询条件提高性能。

**4.** ***\*rows\****：扫描的行数。这个字段表示MySQL预计需要扫描的行数。较小的***\*rows\****值通常意味着更好的性能。如果这个值过大，考虑优化索引或查询条件减少扫描的行数。

**13.** ***\*分布式锁如果业务执行时间过长，锁自动过期了，这种情况怎么处理。\****

锁续租：如果你无法预估业务的执行时间，或者业务执行时间可能非常长，那么你可以采取锁续租的策略。也就是在一个后台线程中，定期检查锁是否即将过期，如果是，则重新设置锁的过期时间。这样可以确保在业务执行过程中，锁始终保持有效。

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps13.jpg) 

可重入锁：如果业务逻辑中有多处需要获取锁的地方，可以考虑使用可重入锁。可重入锁允许同一个线程多次获取同一个锁，而不会导致锁过期。

**14.** ***\*redis命令执行多久视作超时，多大的key可以认为是大key\****

在Redis命令执行的超时时间取决于你的应用和Redis服务器的配置。一般来说，如果一个命令执行时间超过1秒，就可以认为是超时。所谓的"大key"通常指的是key对应的value很大，也就是说，该key存储的数据量很大。对于字符串类型，如果一个key的值超过10KB，那么它就可以被认为是大key。

对于列表、集合、有序集合等复杂数据类型，如果一个key包含的元素数量非常多，例如超过10000个，那么它也可以被认为是大key。

**15.** ***\*kafka怎么限流\****

通过对生产者和消费者的配置进行调整，可以有效地实现限流。下面分别介绍生产者和消费者的限流方法：

\1. 生产者限流：

batch.size：可以设置生产者发送消息的批量大小。通过减小批量大小，可以降低生产者发送消息的速率。但是，过小的批量大小可能导致生产者发送效率降低。

linger.ms：可以设置生产者等待更多消息加入批量的时间。通过增加等待时间，可以降低生产者发送消息的速率。但是，过长的等待时间可能导致生产者发送延迟增加。

\2. 消费者限流：

fetch.min.bytes：设置消费者从Kafka拉取消息的最小字节数。通过增加最小字节数，可以降低消费者拉取消息的速率。但是，过大的最小字节数可能导致消费者拉取延迟增加。

fetch.max.wait.ms：可以设置消费者等待拉取消息的最长时间。通过增加等待时间，可以降低消费者拉取消息的速率。但是，过长的等待时间可能导致消费者拉取延迟增加。

max.poll.records：可以设置消费者每次poll操作返回的最大记录数。通过减小最大记录数，可以降低消费者处理消息的速率。但是，过小的最大记录数可能导致消费者处理效率降低。

***\*深信服一面：\****

**1.** ***\*怎么查看一个进程使用的连接数\****

lsof -a -i -p <PID> | wc -l 

ls -l /proc/<PID>/fd | wc -l

netstat -nptu | grep <PID> | wc -l

**2.** ***\*怎么判断time_wait的数量是不是正常的\****

在通过对HTTP服务器发起请求来判断***\*TIME_WAIT\****数量是否正常可能不是一个准确的方法。***\*TIME_WAIT\****数量受到许多因素的影响，包括服务器的负载、网络状况、应用程序的行为等。因此，仅根据HTTP请求的响应来判断***\*TIME_WAIT\****数量可能会产生误导。

更准确地判断***\*TIME_WAIT\****数量是否正常的方法是：

\1. 直接检查服务器上的***\*TIME_WAIT\****连接数量。你可以使用***\*netstat\****命令来查看***\*TIME_WAIT\****连接的数量，如下所示：

netstat -n | grep TIME_WAIT | wc -l

\2. 监控服务器性能指标，例如CPU使用率、内存使用率和网络吞吐量。如果这些指标在正常范围内，服务器能够正常处理请求，那***\*TIME_WAIT\****的数量可能不是问题。

\3. 如果你发现服务器性能下降，并且***\*TIME_WAIT\****数量过高，那么可能需要进一步调查。在这种情况下，你可以考虑优化TCP参数或应用程序设置，减少***\*TIME_WAIT\****的数量。

**3.** ***\*P\*******\*ing会不会建立握手连接\****

TCP和UDP是传输层协议，它们用于在网络中传输数据。与之相反，ICMP是网络层协议，它用于处理网络中的错误和控制消息。因此ping命令不会建立TCP连接

**4.** ***\*H\*******\*tpp服务可以连接上，但是返回结果一直超时可能是什么原因\****

\1. 在服务器负载过高：如果服务器正在处理大量请求，或者CPU、内存资源不足，可能导致处理速度变慢，从而引起超时。

\2. 网络问题：如果服务器与客户端之间的网络连接不稳定或者带宽不足，也可能导致请求或者响应数据传输慢，引发超时。

\3. 服务端程序问题：如果服务端的处理逻辑存在问题，例如处理某些请求时陷入死循环或者遇到了阻塞操作，也可能导致响应超时。

\4. 数据库或其他依赖服务慢：如果你的应用依赖于数据库或其他服务，而这些服务响应慢或者不可用，也可能导致应用处理请求超时。

\5. 服务器配置问题：服务器的超时设置可能过短，导致正常的请求处理时间超过了这个设置，从而引发超时。

**5.** ***\*G\*******\*o语言结构体有没有内存对齐\****

结构体字段的对齐：Go语言会根据结构体中每个字段的类型来决定其对齐方式。通常，字段的对齐边界是其类型大小的最大因子（最多为8字节）。例如，int32类型的字段会对齐到4字节边界，而指针或int64类型的字段（在64位系统中）会对齐到8字节边界。

**6.** ***\*G\*******\*o语言\*******\*go的包中会有init初始化，如果在go里面有多个init初始化，是一个怎么样的初始化顺序\****

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps14.jpg) 

\1. 首先，***\*main\****包（即包含***\*main\****函数的包）的导入顺序决定了其他包的初始化顺序。换句话说，***\*main\****包中导入的包会先于***\*main\****包初始化。

\2. 如果一个包导入了其他包，则这些被导入的包会先于导入它们的包初始化。

\3. 当一个包中有多个***\*init\****函数时，这些***\*init\****函数会按照声明顺序依次执行。

\1. 按照源文件的名称进行字典序排序。

\2. 对于排序后的每个源文件，按照它们在文件中出现的顺序执行其中的***\*init\****函数。

**7.** ***\*G\*******\*o语言中有哪些阻塞的情况\****

\1. 通道操作：当一个goroutine试图从空的通道接收数据，或者向已满的通道发送数据时，这个goroutine会被阻塞，直到另一个goroutine向通道发送数据或从通道接收数据。

\2. 锁操作：当一个goroutine试图获取已被其他goroutine持有的锁（如sync.Mutex或sync.RWMutex）时，这个goroutine会被阻塞，直到锁被释放。

\3. 系统调用和IO操作：当一个goroutine执行系统调用（如文件操作、网络请求）时，这个goroutine可能会被阻塞，直到系统调用完成。

\4. select语句：当一个goroutine在一个select语句中等待多个通道操作时，这个goroutine会被阻塞，直到其中一个操作可以进行。

\5. 定时器和时间操作：当一个goroutine使用time.Sleep函数或time.Timer等待一段时间时，这个goroutine会被阻塞。

\6. 等待其他goroutine：当一个goroutine使用sync.WaitGroup等待其他goroutine完成时，这个goroutine会被阻塞。

需要注意的是，虽然goroutine在这些情况下会被阻塞，但是Go的运行时会在其他的OS线程上调度并运行其他的goroutine，所以并不会阻塞整个程序的执行。

**8.** ***\*怎么实现对A服务进行灰度的时候，如果命中了A服务同时让A服务中调用的\*******\*B\*******\*服务也命中灰度\****

\1. 设计一个灰度策略，例如基于用户ID、请求头、来源IP等来决定是否命中灰度。这个策略应该在A服务和B服务中都可以使用。

\2. A服务中实现灰度策略。当收到一个请求时，根据灰度策略来判断该请求是否命中灰度。如果命中灰度，将请求路由到A服务的灰度版本。

\3. A服务调用B服务时，将灰度信息传递给B服务。这可以通过多种方式实现，例如在请求头中添加一个特殊的标记，或者在请求参数中添加灰度信息。

\4. 在B服务中实现相同的灰度策略。当收到来自A服务的请求时，检查请求中的灰度信息。如果命中灰度，将请求路由到B服务的灰度版本。

**9.** ***\*协程和线程的区别\****

\1. 管理方式：线程是由操作系统内核管理的，而协程是由程序或运行时库管理的。

\2. 资源开销：线程通常具有较大的资源开销，因为每个线程都需要分配独立的栈空间和其他资源。相比之下，协程的资源开销通常较小，因为它们可以共享同一个线程的栈空间，并在需要时进行切换。

\3. 上下文切换：线程之间的上下文切换涉及到硬件级别的操作，通常具有较高的开销。而协程之间的上下文切换仅涉及到用户级别的操作，因此开销较低。

\4. 调度方式：线程的调度是抢占式的，即操作系统可以在任何时候中断一个线程，将CPU分配给其他线程。而协程的调度通常是协作式的，即一个协程需要显式地将控制权交给另一个协程。

\5. 并发控制：线程之间需要通过互斥锁、信号量等同步原语来进行并发控制，以避免竞争条件。而协程可以通过通道（Channel）等机制来实现并发控制，这通常更容易理解和实现。

 

 

 

 

 

***\*腾讯音乐&光爪网络一面：\****

**1.** ***\*优惠券的具体使用逻辑，优惠券会不会同一个商品使用两张\****

**2.** ***\*支付是怎么防止重复支付成功回调的\****

通过对支付回调的订单号进行校验，会设置一把set nx锁，如果已经存在了，就表示回调是重复的，不会再给用户发奖励

**3.** ***\*不同机器上的时间会不会不一致\****

在使用NTP（Network Time Protocol）：NTP是一种用于同步网络中计算机时间的协议。通过将分布式系统中的所有节点配置为使用相同的NTP服务器，可以使它们的时间保持在一个较小的误差范围内。大多数操作系统都提供了NTP客户端，可以方便地配置和使用。

**4.** ***\*开奖的时候怎么保证开奖后不会有新的进奖池请求用户\****

进奖池前，会通过开奖时间和当前时间的间隔进行判断，判断奖池是否是已经锁住的状态，配置信息是通过定时任务循环拉去数据库配置，写入到本地缓存中的。入奖池前直接判断时间就可以了

**5.** ***\*订阅推送的时候，开始推送了怎么保证不会有新的订阅，开始推会设置一个推送锁\****

推送的时候会变更数据库的赛程状态，未开赛到以开赛，开始推送后用户就无法再订阅了，也不会说存在漏推送的问题

**6.** ***\*K\*******\*afka的topic、partition、consumer之间的关系，数量关系情况\****

**1.** ***\*Topic\****：Topic是Kafka中消息的分类单位。生产者（producer）将消息发布到特定的topic，消费者（consumer）订阅并处理来自特定topic的消息。一个Kafka集群可以包含多个不同的topic。

**2.** ***\*Partition\****：Partition是Kafka中的一个物理概念，用于将topic的数据分散到不同的服务器上。每个topic可以被分成多个partition，每个partition中包含一部分topic的数据。partition中的消息按照它们到达的顺序存储，并分配一个递增的偏移量（offset）。

Kafka通过将一个topic分成多个partition来实现数据的并行处理和高吞吐量。生产者将消息发送到不同的partition，消费者可以并行地从多个partition中读取数据。

**3.** ***\*Consumer\****：Consumer是Kafka中用于订阅和处理消息的实体。一个或多个consumer可以组成一个消费者组（consumer group），消费者组内的每个consumer负责处理topic的一个或多个partition。消费者组中的consumer数量可以小于、等于或大于topic的partition数量。

· 如果consumer数量小于partition数量，那么一个consumer需要处理多个partition的数据。

· 如果consumer数量等于partition数量，那么每个consumer处理一个partition的数据，实现最大并行度。

· 如果consumer数量大于partition数量，那么多余的consumer将处于空闲状态，不会处理任何数据。

总之，Kafka中的topic、partition和consumer之间的关系是：一个topic可以包含多个partition，每个partition可以被一个或多个consumer消费。消费者组中的consumer数量可以根据需要进行调整，以实现不同程度的并行处理。

**7.** ***\*K\*******\*afka用了什么压缩算法来存储数据\****

Kafka支持多种压缩算法，可以在生产者和消费者之间传输压缩过的消息以节省网络带宽和提高吞吐量。Kafka支持的压缩算法包括：

**1.** ***\*Gzip\****：Gzip（GNU zip）是一种广泛使用的压缩算法，提供了较好的压缩比，但压缩和解压缩速度相对较慢。在生产者端，可以通过将***\*compression.type\****参数设置为***\*gzip\****来启用Gzip压缩。

**2.** ***\*Snappy\****：Snappy是Google开发的一种快速压缩算法，旨在提供较快的压缩和解压缩速度，但压缩比相对较低。在生产者端，可以通过将***\*compression.type\****参数设置为***\*snappy\****来启用Snappy压缩。

**3.** ***\*LZ4\****：LZ4是一种快速压缩算法，提供了与Snappy类似的压缩和解压缩速度，但压缩比略高。在生产者端，可以通过将***\*compression.type\****参数设置为***\*lz4\****来启用LZ4压缩。

**4.** ***\*Zstandard（zstd）\****：Zstandard是Facebook开发的一种实时压缩算法，旨在提供较高的压缩比和较快的压缩速度。在生产者端，可以通过将***\*compression.type\****参数设置为***\*zstd\****来启用Zstandard压缩。需要注意的是，Zstandard压缩在Kafka 2.1.0及更高版本中可用。

在实际应用中，需要根据具体的业务需求和系统环境选择合适的压缩算法。例如，如果对压缩速度和解压缩速度有较高要求，可以选择Snappy或LZ4；如果对压缩比有较高要求，可以选择Gzip或Zstandard。在选择压缩算法时，需要权衡压缩速度、解压缩速度、压缩比和资源占用等因素。

 

**8.** ***\*弹幕抽奖不会出现大key吗，为什么不分成小\*******\*key\*******\*随机抽取，虽然是大\*******\*ke\*******\*y，但是只是取有序集合的前一部分元素，不会全部获取。用一个key方便后续数据追溯\****

方便数据回溯，中奖的人数就是有序集合前面的若干人数，不需要额外定位数据，大key的删除是通过定时任务在七天后的低峰期，用游标的方式平缓删除的。

**9.** ***\*先写redis再写数据库，这种场景怎么保证数据的一致性\****

在"先写Redis,然后再写数据库"的场景下，确保数据一致性的挑战在于，如果在写数据库时发生错误（例如数据库服务器宕机或网络中断），则Redis和数据库中的数据将不一致。以下是一些可能的解决策略：

**1.** ***\*重试机制\****：如果写数据库失败，可以尝试重新执行数据库操作。这需要在应用中实现重试逻辑，如设置重试次数和重试间隔等。但是，过多的重试可能会加重数据库的负载。

**2.** ***\*使用事务\****：如果数据库支持事务，可以将写Redis和写数据库的操作放在同一事务中。这样，如果写数据库失败，事务将回滚，Redis中的数据也不会被写入。但是，这需要Redis和数据库支持分布式事务，或者使用某种形式的两阶段提交协议。

**3.** ***\*补偿操作\****：如果写数据库失败，可以执行补偿操作来撤销在Redis中的写入。例如，可以删除Redis中的数据，或者将其标记为无效。然后，可以在后台异步地重试写数据库操作，直到成功。

**4.** ***\*使用队列\****：可以使用消息队列（如Kafka或RabbitMQ）来缓冲写操作。应用首先将写操作发送到队列，然后有一个单独的工作线程（或工作进程）来消费队列中的操作并写入Redis和数据库。如果写数据库失败，工作线程可以重试操作，或者将其放回队列中稍后重试。

请注意，以上解决策略都不能100%保证数据的一致性。在分布式系统中，由于网络分区、延迟等问题，无法保证所有操作都能得到一致和准确的结果。这是CAP定理（一致性、可用性、分区容忍性）中的一个基本限制。在实际应用中，需要根据具体的业务需求和系统环境选择合适的解决策略。

 

 

**10.** ***\*在集群模式redis中，在使用eval脚本操作多个key时，是不是应该家标签让所有的key都落在同一个分片节点上\****

在Redis集群模式中，当你使用EVAL或EVALSHA命令执行Lua脚本操作多个key时，需要确保所有key都落在同一个分片节点上。否则，Redis会报错，提示“CROSSSLOT Keys in request don't hash to the same slot” 

为了确保所有key都落在同一个分片节点上，你可以使用“标签”（也称为“哈希标签”）。标签是一种特殊的key命名规则，它可以让Redis使用指定的部分来计算key的哈希值，从而将具有相同标签的key映射到同一个分片节点。标签的格式是{tag}...，其中{tag}是需要保持一致的部分，...表示其他任意字符。例如，你可以使用以下格式的key：

user:{123}:name user:{123}:age  user:{123}:email

***\*云天畅想一面：\****

**1.** ***\*算法题力扣146 实现\*******\*LRU\*******\*缓存\****

size、len、map、双向链表

**2.** ***\*有一个数组\*******\*arr := [10]int{},slice := [5:6],\*******\*求len\*******\*(slice)\*******\*和cap\*******\*(\*******\*slice\*******\*)\****

len = 1  cap = 5

在Go语言中，当你使用a[i:j]这样的表达式创建一个新的切片时，新切片将引用底层数组a中从索引i（包含）到索引j（不包含）的元素。换句话说，新切片的第一个元素就是底层数组的第i个元素。

在Go语言中，切片的容量（cap）表示从切片的开始位置到底层数组的末尾有多少个元素。底层实现的原因是为了在扩展切片时能够复用底层数组的空间。

当你使用a[i:j]这样的表达式创建一个新的切片时，新切片将引用底层数组a中从索引i（包含）到索引j（不包含）的元素。同时，新切片的容量将从底层数组a的索引i开始计算，直到底层数组的末尾。

在你的示例中，n2是通过n1[5:6]创建的，所以n2的开始位置是n1的索引5。底层数组n1的长度是10，所以从索引5开始到数组末尾（索引9）一共有10 - 5 = 5个元素。因此，cap(n2) = 5。

这样设计的目的是为了在扩展切片时能够复用底层数组的空间。当你向n2添加元素时，如果n2的长度没有超过它的容量，Go可以直接在底层数组n1上添加元素，而不需要重新分配内存。这样可以提高性能，减少内存分配的开销。

**3.** ***\*selcet\*******\*对于nil的通道case是怎么处理的\****

在Go语言中，select语句用于在多个通道操作（发送或接收）中选择一个进行处理。如果select中的一个case对应的通道为nil，那么这个case将被忽略。

具体来说，如果一个case对应的通道为nil，那么这个case的发送或接收操作将永远不会被选中。如果所有的case都对应的通道为nil，并且没有default分支，那么select语句将阻塞，直到至少有一个非nil的通道可用。

**4.** ***\*总结一下操作 channel 的结果\****

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps15.jpg) 

**5.** ***\*为什么如果map中value是一个结构体的时候，不能直接通过结构体修改map中value结构体的值\****

Go语言中，map中的值是不可寻址的。这意味着你不能直接修改map中值的字段。当你尝试执行m[1].Name = "haboo"这样的操作时，Go会报错，提示你不能直接修改map中值的字段对于Go语言中的map，你不能直接修改它的值的字段。也就是说，如果map的值是一个复合类型（如结构体、数组、切片等），你不能直接修改它的字段或元素。

如果你想修改map中值的字段，你需要先将值取出来，修改完后再放回去。m := make(map[int]strduce)

m[1] = strduce{

  Name: "Alice",

  Age:  25,

}m[2] = strduce{

  Name: "Bob",

  Age:  30,

}// 先取出值

v := m[1]// 修改值的字段

v.Name = "haboo"// 

将修改后的值放回去

m[1] = v

fmt.Println(m[1]) // 输出: {haboo 25}

Go语言中，map的底层实现是一个散列表（hash table）。散列表是一种动态数据结构，它可以在运行时根据需要进行扩容和收缩。当向map中添加新元素或者删除元素时，Go可能需要重新分配散列表的内存，并将现有元素移动到新的内存位置。这意味着map中值的内存地址可能会在运行时发生变化。

由于map中值的内存地址可能会发生变化，Go语言设计者决定禁止直接访问map中值的内存地址。这就是为什么map中的值是不可寻址的。这样的设计可以避免潜在的错误，例如，在map中值的内存地址发生变化后，仍然使用旧的内存地址进行操作。

对于简单类型（如int、string等），我们可以直接修改map中的值，因为这些操作不涉及到访问值的内存地址。例如，我们可以直接为map中的键赋一个新的值，或者使用++或--操作符直接修改int类型的值。这些操作是安全的，因为它们不会导致潜在的错误。

**6.** ***\*M\*******\*ap的底层数据结构实现\****

[map 的实现原理 | Go 程序员面试笔试宝典 (golang.design)](https://golang.design/go-questions/map/principal/)

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps16.jpg) 

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps17.jpg) 

**7.** ***\*M\*******\*ap是怎么扩容的，扩容时候的读写是怎么进行的\****

Go语言中的slice切片需要扩容时，是直接一次性完成的

Go语言中的map需要扩容时，是渐进式扩容的

在Go语言中的map在需要扩容时，会创建一个新的底层数组，大小是原数组大小的两倍。然后，Go会将原数组中的元素重新哈希到新的数组中。这个过程被称为"rehashing"。

这个过程可能会消耗一些时间，特别是当map的大小很大时。为了减少这种延迟，Go使用了一种"渐进式哈希"的技术。当map开始扩容时，它不会立即将所有元素移动到新的数组中，而是在接下来的一段时间内，逐渐将元素移动到新的数组中。每次访问map时，Go都会将一部分元素移动到新的数组中。这样，扩容的工作就被分摊到了多次访问操作中，而不是一次性完成。

在扩容过程中，map的读写操作需要一些特殊的处理。当你读取一个键时，Go首先会在新的数组中查找这个键。如果在新的数组中找到了这个键，Go就会返回对应的值。如果在新的数组中没有找到这个键，Go就会在旧的数组中查找这个键，并将这个键及其对应的值移动到新的数组中。当你写入一个键时，Go会直接将这个键及其对应的值写入新的数组中。

**8.** ***\*Go\*******\*语言中recover捕获panic的具体用法\****

**9.** ***\*eval脚本中，如果有多个命令，执行了前两个命令，后面的命令失败了，这种情况下怎么保证事物的一致性\****

在Redis中，EVAL命令执行Lua脚本时，确实不会自动回滚已执行的命令。如果在脚本中有多个命令，并且在执行过程中出现错误，之前已执行的命令不会被回滚，这可能导致数据不一致。为了解决这个问题，您可以在编写Lua脚本时，添加错误处理逻辑。在执行每个命令之前，检查命令的参数和预期结果，如果出现错误，可以通过返回错误信息或使用自定义的回滚逻辑来避免数据不一致。

**10.** ***\*go是怎么实现在同一个线程上运行不同的协程的\****

在Go语言通过使用Goroutine（协程）和调度器来在同一个线程上运行多个协程。Goroutine是一种轻量级的线程，它们的堆栈空间较小，且创建和切换的开销较低。调度器负责管理和调度Goroutine在操作系统线程（也称为M，Machine）上的执行。

以下是Go实现在同一个线程上运行多个协程的基本原理：

\1. 当你创建一个新的Goroutine时，Go会将其添加到调度器的队列中。每个Goroutine都有一个独立的堆栈空间和寄存器状态。

\2. 调度器会在一个或多个操作系统线程上运行。每个线程都有一个P（Processor）实例，它负责执行Goroutine。调度器会根据一定的策略（例如轮询、优先级等）从队列中选择一个Goroutine，并将其分配给一个空闲的P。

\3. P会在当前线程上执行分配给它的Goroutine。在Goroutine运行过程中，它可能会因为I/O操作、系统调用、锁等原因而被阻塞。当这种情况发生时，调度器会将阻塞的Goroutine从当前P上移除，并将另一个Goroutine分配给该P。这样，同一个线程就可以运行多个Goroutine。

\4. 当一个Goroutine完成执行或者因为其他原因被取消时，调度器会将其从队列中移除，并释放其占用的资源。

\5. 调度器会根据系统负载、Goroutine的数量等因素来动态调整线程的数量，以实现更高的并发性能。

**11.** ***\*pipeline执行过程中，中间的命令失败后，会立马就直接返回错误吗，还是会等到所有的命令都执行完了，再返回中间出现的错误\****

在Redis的pipeline操作中，如果中间的某个命令执行失败，Redis不会立即停止执行并返回错误。相反，它会继续执行剩下的命令。然后在最后将所有命令的执行结果（包括成功的结果和失败的错误）一起返回给客户端。

这是因为pipeline操作主要是为了优化网络通信性能，它允许客户端一次性发送多个命令给Redis，然后Redis一次性返回所有命令的执行结果。在这个过程中，Redis并不会在执行每个命令后立即检查是否出错并返回结果。

**12.** ***\*leader节点挂了之后，副本是怎么选出新的领导者节点来的\****

在 Kafka 中，当需要从同步副本（In-Sync Replica，ISR）列表中选择新的领导者时，一般会选择具有最新数据的副本。因为 ISR 列表中的副本都保持着与旧领导者一致的数据，所以任何一个 ISR 都有资格成为新的领导者。

具体的选择策略可能会根据 Kafka 配置和版本有所不同。以下是一些可能的选择策略：

\1. 随机选择：从 ISR 列表中随机选择一个副本作为新的领导者。这种策略简单明了，但可能导致选出的新领导者的负载过高。

\2. 负载均衡：考虑每个副本的负载情况，选择负载较低的副本作为新的领导者。这种策略可以帮助平衡 Kafka 集群的负载，但可能需要额外的负载监控机制。

\3. 数据最新：选择数据最新的副本作为新的领导者。这种策略可以确保新领导者拥有最新的数据，但在数据高度一致的情况下，这个策略的效果可能与随机选择或负载均衡相似。

实际上，由于ISR列表中的所有副本都保持了与旧领导者一致的数据，所以从数据一致性的角度来看，选择哪个副本作为新的领导者并不是关键问题。更重要的是如何快速地完成领导者选举，以减少服务中断的时间，并确保新领导者能够有效地处理生产者和消费者的请求。

**13.** ***\*main线程创建了一个子协程，如果main函数直接退出了，创建的go协程会\*******\*退出吗\****

是的，如果main函数直接退出，那么创建的子协程会被强制退出，即使它们尚未完成任务。当main函数（也就是主协程）结束时，整个程序将终止，所有正在运行的子协程都会被强制退出，无论它们是否已经完成了任务。

**14.** ***\*如果是main函数创建的协程A中，A再创建一个协程B，这种情况下main退出了，AB协程是什么情况\****

在Go语言中，所有的goroutine（包括主goroutine和所有的子goroutine）都是平等的，它们并没有父子关系，也就是说，一个goroutine的生命周期并不受它所在的父goroutine的影响。但是，当主goroutine（也就是main函数）结束时，程序会立即退出，不会等待其他任何goroutine。	

所以，即使是在协程A中创建的协程B，如果main函数退出了，无论是协程A还是协程B，只要它们还在运行，都会被立即终止。

为了避免这种情况，你可以使用sync.WaitGroup或者channel等机制来确保main函数在所有子协程完成任务之前不会退出。

 

 

 

 

 

 

**15.** ***\*go在什么情况下会发生协程的泄漏\****

在Go语言中，协程泄漏（goroutine leak）是指一个协程在执行完任务之后没有正常退出，而是一直占用内存和系统资源。协程泄漏可能导致内存使用不断增加，最终导致程序崩溃或性能下降。

以下是一些可能导致协程泄漏的情况：

\1. 无限循环：如果一个协程中存在无限循环，且没有退出条件或者退出条件很难达到，那么这个协程将永远无法退出，导致协程泄漏。

\2. 阻塞在通道操作：如果一个协程在向通道发送数据或从通道接收数据时被阻塞，而另一个协程没有相应地接收或发送数据，那么这个协程将一直阻塞，导致协程泄漏。

\3. 未处理的select分支：如果一个协程中使用了***\*select\****语句进行多路复用，但没有处理所有分支的情况，那么在某些情况下，协程可能会一直阻塞，导致协程泄漏。

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps18.jpg)![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps19.jpg) 

**16.** ***\*一个后台go服务的启动，从最开始到启动完成的流程是怎么样的\****

一个后台Go服务从启动到运行完成的流程通常包括以下几个阶段：

\1. 初始化：在这个阶段，服务会加载配置文件、初始化日志系统、设置环境变量等。这些操作通常在***\*main\****函数的开始部分完成。

\2. 创建依赖服务：服务可能需要访问数据库、缓存、消息队列等外部资源。在这个阶段，服务会创建连接池、客户端实例等，以便于后续访问这些资源。

\3. 注册路由和中间件：对于Web服务或API服务，需要定义路由以及注册中间件。路由用于将请求映射到相应的处理函数，中间件用于在处理请求之前或之后执行一些通用操作，如身份验证、日志记录等。

\4. 启动协程：服务可能需要启动一些后台协程来执行定时任务、消息处理等。这些协程通常在***\*main\****函数中使用***\*go\****关键字启动。

\5. 启动HTTP服务：对于Web服务或API服务，需要启动一个HTTP服务器来监听客户端请求。

\6. 优雅关闭：为了确保在服务关闭时能够优雅地处理正在进行的请求，可以捕获操作系统的信号（如SIGINT或SIGTERM），并使用***\*http.Server\****类型的***\*Shutdown\****方法来实现优雅关闭。

**17.** ***\*为什么MySQL选择B+树而不是红黑树作为索引结构的原因\****

\1. 在磁盘I/O优化：数据库系统通常需要存储大量的数据，这些数据通常无法全部放入内存中，而需要存储在磁盘上。B+树的一个显著特点是每个节点可以包含多个键值对，这使得B+树的每个节点可以充分利用磁盘块的空间。相比之下，红黑树是一种二叉树结构，每个节点只包含一个键值对，这意味着红黑树的高度通常比B+树要高，从而导致更多的磁盘I/O操作。

\2. 范围查询优化：B+树的叶子节点之间通过指针相互连接，这使得B+树在进行范围查询时具有较高的性能。当需要查询一个范围内的数据时，B+树可以通过顺序遍历叶子节点来获取这些数据。而红黑树没有这种顺序存储结构，因此在进行范围查询时需要遍历整个树结构，效率较低。

\3. 空间局部性：由于B+树的节点可以容纳多个键值对，这使得查询时具有较好的空间局部性。空间局部性指的是在访问数据时，相邻的数据具有较高的访问概率。B+树的这种特性有助于减少缓存未命中和磁盘I/O操作。而红黑树由于其二叉结构，空间局部性较差。

\4. 更好的扩展性：B+树具有更好的扩展性，因为它可以通过调整阶数来适应不同的数据量和查询需求。而红黑树作为一种二叉树结构，其扩展性相对较差。

总之，MySQL数据库中，InnoDB存储引擎选择了B+树作为索引结构，而不是红黑树，这主要是因为B+树在磁盘存储、查询性能、空间局部性和扩展性方面具有优势。

**18.** ***\*红黑树有多少阶\****

红黑树是一种自平衡的二叉查找树，它本身并没有阶的概念。阶数这个概念通常用于描述B树或B+树，表示一个节点最多可以有多少个子节点。

然而，红黑树有一些特性和性质，这些性质确保了红黑树在插入、删除和查找操作时能保持相对平衡，从而提供良好的查询性能。红黑树的性质如下：

\1. 节点是红色或黑色。

\2. 根节点是黑色。

\3. 所有叶子节点（通常是空节点或者NULL节点）是黑色。

\4. 每个红色节点的两个子节点都是黑色。换句话说，从每个叶子节点到根节点的所有路径上不能有两个连续的红色节点。

\5. 从任一节点到其每个叶子节点的所有简单路径都包含相同数量的黑色节点。

由于红黑树的这些性质，它的最长路径不会超过最短路径的2倍。这意味着红黑树的高度在最坏情况下也不会超过2 * log2(N+1)，其中N是树中节点的数量。这样可以保证红黑树在插入、删除和查找操作时具有O(log N)的时间复杂度。

**19.** ***\*B+数最多有多少层\****

B+树的层数与其阶数（即每个节点最多有多少个子节点）以及节点的填充率（即实际子节点数量占最大子节点数量的比例）有关。

理论上，B+树的层数没有上限，可以随着数据量的增加而增加。但在实际应用中，由于磁盘I/O操作的代价很高，数据库系统通常会选择一个适当的阶数，使得B+树的层数尽可能地小，以减少磁盘I/O操作的次数。

例如，假设我们有一个阶数为100的B+树，且每个节点的填充率为100%。那么：

· 在第1层（根节点），我们有1个节点。

· 在第2层，我们有100个节点。

· 在第3层，我们有100 * 100 = 10,000个节点。

· 在第4层，我们有100 * 100 * 100 = 1,000,000个节点。

所以，对于一个拥有百万条记录的数据库，如果使用阶数为100的B+树，我们只需要4层就可以存储所有的记录。这就是B+树在数据库系统中广泛使用的原因之一。

然而，需要注意的是，这只是理论上的计算。在实际应用中，由于不可能总是保证每个节点的填充率达到100%，B+树的实际层数可能会比理论计算的结果要多。

**20.** ***\*go语言初始化一个空struce和一个布尔类型的变量谁占用的空间大\****

在Go语言中，初始化一个空结构体（struct{}）和一个布尔类型（bool）的变量时，通常情况下，布尔类型变量占用的空间会更大。

**·** ***\*空结构体（struct{}）\****：空结构体不包含任何字段，因此其大小（size）为0。这意味着在内存中，它本身不占用任何用于存储数据的空间。然而，当你声明一个空结构体的变量时，这个变量本身（包括其类型信息和可能的元信息）需要被跟踪，但这通常是通过编译器和运行时环境的内部机制来处理的，并不直接对应于在堆或栈上分配的内存。

**·** ***\*布尔类型（bool）\****：布尔类型用于表示真（true）或假（false）的值。在Go中，布尔类型通常占用1个字节（8位）的内存空间。这是因为布尔值需要被存储在内存的最基本单元——字节中。

因此，从直接占用内存的角度来看，布尔类型变量占用的空间比空结构体变量大。然而，这种差异非常小，对于大多数应用来说几乎可以忽略不计。

需要注意的是，这里的比较是基于单个变量的情况。如果你将空结构体或布尔类型作为结构体字段、数组元素或切片元素等，那么它们的内存占用可能会受到内存对齐等因素的影响，但这与它们作为单独变量时的内存占用不同

**21.** ***\*Go语言的内存对齐是怎么样的，go的内存对齐和C++的内存对齐有区别吗\****

Go语言的内存对齐（Memory Alignment）是指在为变量分配内存时，根据变量类型的大小自动调整其在内存中的起始地址，使其地址是类型大小的整数倍。内存对齐旨在提高内存访问效率，因为许多处理器在访问特定地址对齐的数据时性能更佳。

Go语言的内存对齐遵循以下规则：

\1. 基本类型：对于基本类型（如int、float、pointer等），其内存对齐大小等于其类型大小。例如，int32类型的变量会对齐到4字节边界，int64类型的变量会对齐到8字节边界。

\2. 结构体：结构体中的字段按照其在结构体中声明的顺序进行内存分配。每个字段根据其类型大小进行对齐，同时整个结构体的对齐大小为其最大字段类型的对齐大小。结构体的总大小是其对齐大小的整数倍。

\3. 数组：数组的内存对齐与其元素类型的内存对齐相同。例如，一个int32类型的数组会对齐到4字节边界。

\4. 切片、映射和通道：这些复合类型的内存对齐与指针类型相同，通常为4字节（32位系统）或8字节（64位系统）。

为了提高内存访问效率，可以在定义结构体时注意字段的顺序，将较大的字段类型放在前面，较小的字段类型放在后面。这样可以减少因内存对齐导致的内存浪费。

示例：以下是一个关于Go语言内存对齐的代码示例。在这个例子中，我们定义了两个结构体，并通过unsafe.Sizeof()函数查看它们的内存大小。我们可以观察到，通过调整结构体字段的顺序，可以减少内存浪费。

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps20.jpg) 

在这个示例中，结构体A的字段顺序导致了内存浪费。由于bool类型字段a占用1字节，之后的int32类型字段b需要对齐到4字节边界，因此会有3字节的内存空间被浪费。调整顺序后，结构体B的内存大小减少了，从而减少了内存浪费。首先，结构体的内存对齐规则是：结构体的对齐值等于其最大字段的对齐值。结构体的大小必须是其对齐值的整数倍。

在***\*StructA\****中，***\*bool\****类型字段***\*a\****占用1字节，然后是***\*int32\****类型字段***\*b\****，需要对齐到4字节边界，所以在***\*a\****和***\*b\****之间有3字节的填充。***\*b\****占用4字节。接下来是***\*float64\****类型字段***\*c\****，需要对齐到8字节边界，所以在***\*b\****和***\*c\****之间有4字节的填充。***\*c\****占用8字节。所以，***\*StructA\****的总大小是1（a）+ 3（填充）+ 4（b）+ 4（填充）+ 8（c）= 20字节。

然而，因为***\*StructA\****的对齐值是8（由最大字段***\*float64\****决定），所以***\*StructA\****的大小必须是8的倍数。因此，***\*StructA\****的实际大小是24字节，而不是20字节，多出的4字节是为了满足对齐要求的填充。

**22.** ***\*有一个channlM个读协程，M个写协程，保证正常关闭channl\****

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps21.jpg)![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps22.jpg) 

在这个修改后的示例中，我们为读协程引入了一个额外的***\*sync.WaitGroup\****（***\*readWg\****）。在启动读协程时，我们调用***\*readWg.Add(1)\****来增加等待计数。在每个读协程的***\*readResource\****函数中，我们使用***\*defer readWg.Done()\****来在协程完成时减少等待计数。在***\*main\****函数中，我们调用***\*readWg.Wait()\****来等待所有读协程完成。这样，当所有写协程完成并关闭channel后，读协程会在处理完所有数据后退出，而不会阻塞。

**23.** ***\*如果在写协程中，可能会出现又新建一个协程去写chan，这种情况应该怎么处理\****

为了处理在写协程中可能出现的新建协程写入channel的情况，我们可以使用一个原子计数器（sync/atomic包中的atomic.AddInt32）来跟踪活跃的写协程数量。当活跃写协程数量为0时，关闭channel。以下是一个示例：

package main

 

import (

​	"fmt"

​	"math/rand"

​	"sync"

​	"sync/atomic"

​	"time"

)

 

var sharedResource int

 

func readResource(id int, ch <-chan int, wg *sync.WaitGroup) {

​	defer wg.Done()

 

​	for v := range ch {

​		fmt.Printf("Goroutine %d read shared resource: %d\n", id, v)

​	}

}

 

func writeResource(id int, ch chan<- int, activeWriters *int32) {

​	defer atomic.AddInt32(activeWriters, -1)

 

​	sharedResource = rand.Intn(100)

​	fmt.Printf("Goroutine %d write shared resource: %d\n", id, sharedResource)

​	ch <- sharedResource

 

​	// 在此处创建新的写协程，如果需要

}

 

func main() {

​	rand.Seed(time.Now().UnixNano())

 

​	var writeWg, readWg sync.WaitGroup

​	var activeWriters int32

​	ch := make(chan int)

 

​	// 启动5个读协程

​	for i := 1; i <= 5; i++ {

​		readWg.Add(1)

​		go readResource(i, ch, &readWg)

​	}

​	// 启动5个写协程

​	for i := 6; i <= 10; i++ {

​		atomic.AddInt32(&activeWriters, 1)

​		writeWg.Add(1)

​		go func(id int) {

​			defer writeWg.Done()

​			writeResource(id, ch, &activeWriters)

​		}(i)

​	}

​	// 启动一个单独的协程来等待所有写协程的完成，然后关闭channel

​	go func() {

​		writeWg.Wait()

​		for {

​			if atomic.LoadInt32(&activeWriters) == 0 {

​				close(ch)

​				break

​			}

​			time.Sleep(10 * time.Millisecond)

​		}

​	}()

​	// 等待所有读协程完成

​	readWg.Wait()

}

在这个示例中，我们使用sync/atomic包中的atomic.AddInt32原子操作来跟踪活跃的写协程数量。当启动一个新的写协程时，我们调用atomic.AddInt32(&activeWriters, 1)来增加活跃写协程计数。在每个写协程的writeResource函数中，我们使用defer atomic.AddInt32(activeWriters, -1)来在协程完成时减少活跃写协程计数。

我们启动了一个单独的协程来监控activeWriters计数。当所有写协程完成且activeWriters计数为0时，我们关闭channel。这样，无论何时创建新的写协程，只要跟踪活跃写协程计数，我们就可以确保在所有写协程完成后关闭channel。s

***\*柚乐科技一面：\****

***\*1. 为什么是删除缓存而不是更新缓存\****

​	在并发的缓存一致性问题上，删除缓存相较于更新缓存更加合适的原因主要体现在以下几个方面：

一、操作复杂性与效率

更新缓存的复杂性：

更新缓存可能需要复杂的逻辑来确保数据的一致性，特别是在缓存数据结构复杂或缓存更新频繁的场景下。这种复杂性可能导致更多的出错机会和性能瓶颈。

更新缓存还需要考虑缓存失效策略，如何确保缓存中的数据在适当的时候被更新或清除，以避免数据不一致。

删除缓存的简洁性：

删除缓存的操作相对简单，只需从缓存中移除相应的数据项即可。

删除缓存后，下次访问该数据时，系统会自动从数据库等数据源中重新加载数据到缓存中，从而保证了数据的一致性。

二、并发场景下的表现

更新缓存的并发问题：

在高并发的场景下，多个请求可能同时尝试更新同一缓存项。如果更新操作不是原子的，就可能导致数据竞争和不一致的问题。

即使在更新操作是原子的情况下，也可能因为网络延迟、系统负载等原因导致更新操作在不同请求之间的顺序不一致，从而引发数据不一致的问题。

删除缓存的并发优势：

删除缓存的操作通常是原子的，可以很容易地在并发环境中执行而不会导致数据竞争。

删除缓存后，每个请求都会根据自己的需要独立地从数据源中加载数据到缓存中，从而避免了并发更新时可能出现的数据不一致问题。

三、一致性与性能的权衡

更新缓存的一致性与性能：

更新缓存可以确保缓存中的数据与数据源保持一致，但在高并发场景下可能会对性能产生影响。频繁地更新缓存会增加系统的负担和延迟，特别是在缓存数据结构复杂或更新逻辑繁琐的情况下。

删除缓存的权衡：

删除缓存虽然会导致一次性的Cache Miss（缓存未命中），但可以通过优化数据源的读取性能和缓存的重建策略来减少这种影响。在大多数情况下，删除缓存后的第一次访问可能会稍微慢一些，但从第二次访问开始就可以享受到缓存带来的性能优势了。

综上所述，删除缓存之所以在并发的缓存一致性问题上更加合适，主要是因为其操作简洁、易于并发控制，并且能够在一定程度上权衡一致性与性能之间的关系。当然，在实际应用中还需要根据具体的业务场景和需求来选择最合适的缓存策略。

***\*2. 排行榜用redis的zset结构怎么实现相同时间下先到的排在前面\****

​	redis的zset是一个很好的排序工具,他会以member - score 的形式来排序,但是,当分数相同的时候,是按照member的字典序来排的	

（a）.此时应该让Score存一个分数值，然后再拼接一个未来时间减去当前时间的的时间戳，这样话就能实现加入的时间戳越小的情况下，反而分数值越高。要进行分数增加的话，把操作放在一个eval脚本里面去保证原子性。

（b）score = 分数 + 1-时间戳/1e13

为了实现分数相同按照时间顺序排序，**我们可以将分数score设置为一个浮点数，其中整数部分为得分，小数部分为时间戳**，如下所示：

\> score = 分数 + 时间戳/1e13

假设现在的时间戳是1680417299000，除以1e13得到0.1680417299000，再加上一个固定的分数（比如10），那么最终的分数就是10.1680417299000，可以将它作为zset中某个成员的分数，用来排序。

这么做了之后，假如有四个数字：

10.1680417299000、10.1680417299011、11.1680417299000、11.1680417299011

他们按照倒序拍完顺序之后，会是：

11.1680417299011>11.1680417299000>10.1680417299011>10.1680417299000

实现了分数倒序排列，分数相同时间戳大的排在了前面，这和我们的需求相反了，所以，就需要在做一次转换。

\> score = 分数 + 1-时间戳/1e13

\> 因为时间戳是这种形式1708746590000 ，共有13位，而1e13是10000000000000，即1后面13个0，所以用时间戳/1e13就能得到一个小数

这样可以保证分数相同时，按照时间戳从小到大排序，即先得分的先被排在前面。

***\*3.\**** ***\*弹幕的敏感词过滤，怎么实现再有很多的敏感词的情况下，能够快速的进行校验过滤\****

a. 敏感词表构建

Trie树（前缀树）：使用Trie树来存储敏感词列表。Trie树非常适合处理字符串的查找问题，特别是当需要查找大量字符串中的公共前缀时。在Trie树中，每个节点代表一个字符，从根节点到某个节点的路径构成了一个字符串。这样，你可以通过遍历Trie树来检查一个词是否包含敏感词，且时间复杂度较低。

AC自动机（Aho-Corasick自动机）：AC自动机是Trie树的扩展，用于多模式匹配。它增加了失败指针（fail pointer），使得当某个单词不匹配时，可以快速跳转到另一个可能的匹配点。这对于处理大量敏感词非常有效。

b. 文本分割与匹配

分词：对于中文文本，首先需要进行分词处理，因为中文单词之间没有明显的分隔符。可以使用成熟的分词工具如jieba分词等。

滑动窗口匹配：使用滑动窗口技术来遍历文本，将每个窗口内的内容（可能是一个单词或多个单词的组合）与敏感词表进行匹配。

c. 高效匹配算法

KMP算法：虽然KMP算法主要用于单个字符串匹配，但在某些场景下，如敏感词数量不多且文本较长时，结合Trie树或AC自动机使用，可以进一步提高效率。

Boyer-Moore算法：一种高效的字符串匹配算法，特别适用于长文本中搜索较短的字符串模式。虽然它主要用于单模式匹配，但可以通过一些技巧应用于多模式匹配场景。

***\*4.\**** ***\*消费者的offest是先提交再处理业务逻辑还是先处理业务逻辑再提交offest\****

推荐做法：先处理业务逻辑再提交offset。这样可以确保只有在业务逻辑成功处理之后，offset才会被提交，从而避免消息丢失的风险。

特殊情况：在某些特定的业务场景下，如果业务逻辑处理失败对系统的影响较小，或者可以通过其他方式（如死信队列）来处理失败的消息，那么也可以考虑在业务逻辑处理之前提交offset，但这种情况较为少见且需要谨慎处理。

***\*5.\**** ***\*空接口有什么属性嘛\****

​	空接口（interface{}）在Go语言中是一种特殊的接口类型，它没有任何方法需要被实现。由于它不要求实现任何方法，因此任何类型都隐式地实现了空接口，即任何值都可以赋给空接口类型的变量。

关于空接口的属性，从技术上讲，空接口本身并不直接拥有属性，而是其底层实现和运行时行为使其能够“存储”任何类型的值。具体来说，空接口在Go语言中的底层实现通常涉及到两个主要部分：

**1.** ***\*类型信息（Type Information）\****：空接口变量内部会存储一个指向其当前存储值的类型信息的指针。这个类型信息用于在运行时进行类型检查和反射等操作。

**2.** ***\*数据指针（Data Pointer）\****：空接口变量还包含一个指向其当前存储值的实际数据的指针。这个指针指向内存中的一个位置，该位置存储了变量的具体值。

这种底层实现方式使得空接口能够“存储”任何类型的值，因为无论值的类型是什么，都可以通过类型信息和数据指针来表示。

然而，从用户的角度来看，我们并不直接操作这些底层属性。相反，我们通过类型断言（Type Assertion）或类型选择（Type Switch）等机制来从空接口变量中提取出具体的值或类型信息。

总结来说，空接口本身没有直接的属性，但其底层实现通过类型信息和数据指针来支持其存储任何类型值的能力。这种设计使得空接口在Go语言中非常灵活和强大，被广泛用于实现多态、泛型编程（通过反射和接口）等高级功能。

 

 

***\*联通一面：\****

**1.** ***\*接口的特点是什么\****

在Go语言中的接口（interface）是一种非常灵活和强大的特性，其特点主要体现在以下几个方面：

抽象性和灵活性

定义方法集合：接口定义了一组方法的集合，但没有具体的实现。这使得接口成为一种抽象的数据类型，它描述了对象的行为，而不关心对象的具体类型。隐式实现：Go语言的接口是隐式实现的，这意味着一个类型只要实现了接口中定义的所有方法，就被认为是实现了该接口，而无需显式声明。这种设计提高了代码的灵活性和可扩展性。

多态性

多态性支持：接口类型可以用来实现多态性，使得不同类型的对象可以以相同的接口类型来操作。这增强了代码的可复用性和可维护性。

灵活性和扩展性

非侵入式：Go语言的接口是非侵入式的，即一个类型可以在不知道接口存在的情况下实现该接口。这降低了类型与接口之间的耦合度，使得代码更加灵活。

组合接口：一个接口可以包含其他接口的所有方法，这允许接口之间的组合，从而实现了接口的多态和扩展性。

广泛应用

多领域应用：接口在Go语言中有着广泛的应用，包括网络编程、并发编程、测试、框架开发等。例如，在网络编程中，接口可以用于定义各种网络协议的通信方式；在并发编程中，接口可以用于定义各种并发模式的接口。

空接口与非空接口

空接口：空接口（interface{}）是一种特殊的接口类型，它没有任何方法，因此可以表示任何类型的值。空接口在Go语言中常用于存储任意类型的值或作为函数参数的通用类型。

非空接口：非空接口则是指至少有一个方法的接口类型。只有实现了接口中定义的所有方法的类型才能赋值给该非空接口变量。

底层实现

数据结构：在Go语言的实现中，接口值是由一个具体类型和一个具体值组成的。对于空接口，其底层数据结构是eface，包含类型信息和值指针；对于非空接口，其底层数据结构是iface，包含类型信息（itab指针）和值指针。

综上所述，Go语言的接口具有抽象性、灵活性、多态性、扩展性等特点，并且广泛应用于各种编程领域。这些特点使得Go语言成为一种高效、可维护且易于扩展的编程语言。

**2.** ***\*接口是怎么自动找到对应的方法的\****

在Go语言中，接口能够自动找到对应的方法，这一机制是通过Go的类型系统和运行时（runtime）的反射（reflection）能力共同实现的，但主要依赖于类型系统的静态分析和编译时的类型检查。具体来说，接口如何自动找到对应的方法，主要基于以下几个关键点：

接口定义与方法集合

接口在Go中被定义为一组方法的集合，这些方法不包含实现（即没有函数体），仅作为类型应该实现的契约。

当一个类型（通常是结构体或其他自定义类型）实现了接口中声明的所有方法时，我们就说这个类型“实现了”该接口。这里的“实现”是隐式的，不需要显式声明。

编译时类型检查

在编译时，Go编译器会检查每个接口变量的赋值操作，确保被赋值的类型确实实现了接口中声明的所有方法。

如果一个类型没有实现接口中的所有方法，编译器会报错，指出类型与接口不匹配。

接口与具体类型的关联

在Go中，接口变量实际上存储的是对具体类型值的引用（以及该值的类型信息，对于非空接口而言）。这种设计允许接口变量在运行时动态地引用不同类型的值，只要这些类型实现了接口。当通过接口变量调用方法时，Go运行时（runtime）会根据接口变量中存储的具体类型信息，找到对应类型的方法实现，并执行它。

反射（Reflection）的作用

虽然反射在接口自动找到对应方法的过程中不是必需的（主要依赖于编译时类型检查和运行时类型信息），但它提供了一种在运行时检查和操作对象类型及其方法的手段。

通过反射，我们可以在运行时查询一个接口变量所引用的具体类型，以及该类型实现了哪些方法。然而，这通常不是接口自动找到方法的主要机制。

示例说明

假设我们有一个接口Shape和一个实现了该接口的类型Circle：

 

go

type Shape interface {  

  Area() float64  

}  

 

type Circle struct {  

  radius float64  

}  

 

func (c Circle) Area() float64 {  

  return math.Pi * c.radius * c.radius  

}  

 

func main() {  

  var s Shape = Circle{radius: 5}  

  fmt.Println(s.Area()) // 输出圆的面积  

}

在这个例子中，当s.Area()被调用时，Go编译器知道s是一个Shape接口类型的变量，并在编译时检查Circle类型是否实现了Area方法。在运行时，Go运行时根据s中存储的具体类型信息（这里是Circle），找到Circle类型的Area方法实现，并执行它。

总结Go语言通过编译时类型检查和运行时类型信息，实现了接口自动找到对应方法的能力。这种设计既保证了类型安全，又提供了高度的灵活性和动态性。

**3.** ***\*明确一个变量不需要使用了之后，怎么加速垃圾回收，代码中怎么写\****

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps23.jpg) 

 

 

 

**4.** ***\*返回函数的引用的话，一定会导致内存逃逸吗\****

在Go语言中，返回函数的引用不一定会导致内存逃逸，但具体是否发生逃逸取决于多个因素。内存逃逸通常发生在以下几种情况：

变量的生命周期超出其作用域：当一个局部变量在函数返回后仍然被外部引用时，这个变量就会发生逃逸。如果返回的是函数的引用（即函数值），而这个函数值内部没有引用任何外部变量或逃逸的变量，那么它本身通常不会直接导致内存逃逸。但是，如果这个函数值内部引用了外部变量或逃逸的变量，那么这些被引用的变量可能会逃逸。

闭包引用：在Go中，闭包可以捕获外部变量。如果闭包被返回，并且闭包内部引用了外部变量，那么这些外部变量可能会逃逸到堆上，因为闭包的生命周期可能超出了外部变量的原始作用域。

编译器优化和逃逸分析：Go编译器在编译时会进行逃逸分析，以确定哪些变量需要在堆上分配内存。逃逸分析的结果会影响变量的内存分配位置。如果编译器认为某个变量在函数返回后仍然可能被引用，那么它可能会将该变量分配到堆上，从而导致内存逃逸。

对于返回函数引用的情况，如果这个函数引用没有捕获任何外部变量或逃逸的变量，那么它本身通常不会导致内存逃逸。然而，如果这个函数引用内部使用了外部变量或逃逸的变量，并且这些变量在函数返回后仍然被需要，那么这些变量可能会逃逸到堆上。

为了避免不必要的内存逃逸，可以采取以下措施：

尽量减少在函数内部创建大的数据结构或复杂的对象，这些对象更容易导致内存逃逸。

尽量避免在函数内部创建闭包，并返回闭包引用，除非确实需要这样做。

使用值传递而不是引用传递，当可能时，将数据作为值返回而不是返回其引用。

使用Go编译器的逃逸分析工具（通过-gcflags="-m"编译参数）来检查和优化代码，以减少内存逃逸。

综上所述，返回函数的引用不一定会导致内存逃逸，但具体是否发生逃逸取决于函数内部是否引用了外部变量或逃逸的变量，以及编译器的逃逸分析结果。

**5.** ***\*怎么分析go的内存泄露\****

 

**6.** ***\*Make和new的区别\****

在Go语言中，make 和 new 是两个用于内存分配的内置函数，但它们之间存在几个关键的区别。这些区别主要体现在它们分配内存的对象类型、初始化方式以及返回值的类型上。

分配对象类型

new：new 函数用于分配内存。它接受一个类型 T 作为参数（不是类型的值或指针），并返回该类型的一个零值指针 *T。new 总是返回指针，指向分配了零值的内存空间。它仅用于基本类型（如int、float64等）和复合类型（如结构体、数组等）的指针分配。对于切片、映射（map）和通道（channel），应该使用 make 而不是 new，因为 new 不会初始化这些复合类型的内部结构。

make：make 函数用于初始化内置的数据结构类型，如切片（slice）、映射（map）和通道（channel）。对于这三种类型，make 会返回初始化后的（非零）值，而不是指针。对于切片，make 会分配一个元素数组并初始化切片结构来引用这个数组；对于映射，make 会分配一个哈希表；对于通道，make 会初始化通道的内部数据结构并准备好通信。

返回值

new：返回指向类型的指针（*T），该指针指向的内存被初始化为该类型的零值。

make：返回初始化后的值（对于切片、映射和通道），不是指针。对于切片，它返回切片类型（[]T）；对于映射，返回映射类型（map[K]V）；对于通道，返回通道类型（chan T）

 

初始化

new：仅分配内存，将内存初始化为类型的零值。不会初始化切片、映射或通道的内部结构。

make：除了分配内存外，还初始化切片、映射或通道的内部数据结构。例如，make([]int, 10) 会分配一个长度为10的切片，并初始化其底层数组。

示例

go

// 使用new  

var p *int = new(int)  

*p = 10 // 需要先解引用  

 

// 使用make  

s := make([]int, 0, 10) // 分配一个长度为0，容量为10的切片  

s = append(s, 1)     // 直接使用，无需解引用  

 

m := make(map[string]int)  

m["one"] = 1 // 直接使用，无需解引用  

 

ch := make(chan int)  

// ... 使用通道

总结来说，new 和 make 都用于内存分配，但它们的用途和返回值的类型不同。new 主要用于基本类型和复合类型的指针分配，而 make 用于初始化切片、映射和通道等内置数据结构。

**7.** ***\*Go语言的结构体初始化是怎么样的\****

在Go语言中，结构体的初始化可以通过多种方式完成，这取决于你的具体需求。结构体是Go中一种复合数据类型，它允许你将多个不同类型的项组合成一个单一的类型。

以下是几种常见的结构体初始化方式：

使用字面量初始化

这是最直接和常用的初始化方式。你可以直接在声明变量时，使用结构体字面量来初始化结构体的字段。

go

type Person struct {  

  Name string  

  Age  int  

}  

func main() {  

  p1 := Person{Name: "Alice", Age: 30}  

  // 或者，如果字段顺序与结构体中定义的顺序一致，可以省略字段名  

  p2 := Person{"Bob", 25}  

  fmt.Println(p1, p2)  

}

 

使用new关键字

new关键字会为结构体分配内存空间，并返回指向该空间的指针，但不会自动初始化结构体的字段（即字段会被设置为零值）。

go

p := new(Person)  

p.Name = "Charlie"  

p.Age = 35  

fmt.Println(*p)

注意，这里new(Person)返回的是*Person类型的指针，因此你需要通过指针来访问和修改结构体的字段。

使用工厂函数

对于复杂的结构体或者需要执行额外初始化步骤的结构体，你可以定义一个工厂函数来返回结构体的实例。

go

func NewPerson(name string, age int) Person {  

  return Person{Name: name, Age: age}  

}  

func main() {  

  p := NewPerson("David", 40)  

  fmt.Println(p)  

}

结构体切片和映射的初始化

虽然这不是直接对结构体本身的初始化，但在处理结构体的集合时非常有用。

go

// 结构体切片  

people := []Person{  

  {"Eve", 28},  

  {"Frank", 32},  

}  

// 结构体映射（以Name为键）  

peopleMap := make(map[string]Person)  

peopleMap["Eve"] = Person{Name: "Eve", Age: 28}

底层实现

Go语言的结构体初始化在底层主要是通过内存分配和赋值操作完成的。当你使用字面量初始化结构体时，Go会首先为结构体分配足够的内存空间以存储其所有字段，然后按照字段的顺序和类型，将字面量中提供的值复制到相应的内存位置。

对于使用new关键字的情况，Go会分配足够的内存来存储整个结构体（即结构体的所有字段所占用的内存总和），并返回指向该内存地址的指针。但请注意，new不会自动初始化结构体的字段，字段的初始值是它们类型的零值。

工厂函数和结构体切片、映射的初始化在底层也是基于这些基本的内存分配和赋值操作来实现的，但它们提供了更高级别的抽象和便利性。

**8.** ***\*gc是什么过程\****

Go语言的GC（Garbage Collection，垃圾回收）是自动内存管理的一个核心机制，用于回收程序中不再使用的内存空间。Go语言的GC过程主要基于“标记-清除”（Mark-Sweep）算法，但随着版本的迭代，其实现方式不断优化，引入了并发标记、三色标记法以及写屏障等技术，以提高垃圾回收的效率和减少STW（Stop The World，即程序暂停执行以进行垃圾回收的时间）时间。

Go语言的GC过程大致可以分为以下几个阶段（以较新版本的实现为例）：

**1.** ***\*标记准备阶段\****：

o GC开始执行前的准备工作，包括暂停程序运行，以便扫描和标记活跃对象。

o 扫描所有的根对象（如全局变量、栈上的变量等），并将它们放入标记队列中。

**2.** ***\*并发标记阶段\****：

o 在此阶段，GC与程序运行并发进行，以减少STW时间。

o 从标记队列中取出对象，标记为“已访问”（或称为“灰色”），并递归地遍历其引用的所有对象，将它们也标记为灰色，并放入标记队列中。

o 同时，通过写屏障技术跟踪对象引用关系的变化，确保在并发标记过程中新创建或修改的引用关系也能被正确标记。

**3.** ***\*标记调整阶段\****（可能包含多个小阶段，如处理写屏障产生的额外标记等）：

o 在并发标记阶段之后，可能需要进一步处理因程序运行而产生的新的引用关系变化。

o 通过STW来确保标记结果的准确性，处理并发标记阶段中遗漏或新增的引用关系。

**4.** ***\*清除阶段\****：

o 遍历堆内存，清除所有未被标记为活跃的对象（即“白色”对象），释放其占用的内存空间。

o 此阶段通常需要STW，以确保在清除过程中不会有新的对象被创建或引用关系被修改。

**5.** ***\*内存整理阶段\****（在某些版本的Go中可能不是必需的）：

o 如果堆内存中产生了大量的碎片空间，GC可能会进行内存整理，将存活的对象移动到堆的一端，形成连续的内存块。

o 这有助于减少内存碎片，提高内存分配的效率。

Go语言的GC还包含了一些优化机制，如三色不变式（强三色不变式和弱三色不变式）和混合写屏障（插入写屏障和删除写屏障），以确保在并发标记过程中对象引用关系的正确性，并尽可能减少STW时间。

总的来说，Go语言的GC过程是一个复杂但高效的内存管理机制，它通过不断优化算法和引入新技术来提高垃圾回收的效率和减少程序暂停的时间，从而为开发者提供更为流畅和高效的编程体验。

**9.** ***\*where in元素过多的话会有什么问题\****

当WHERE IN子句中的元素过多时，会面临一系列问题和挑战，这些问题主要涉及到性能、资源利用以及数据库的限制。以下是一些具体的问题：

**1.** ***\*性能下降\****：

**o** ***\*查询速度慢\****：随着IN子句中元素数量的增加，数据库需要执行更多的比较操作来确定哪些记录符合条件。这些比较操作会消耗大量的CPU资源，并导致查询响应时间显著增加。

**o** ***\*索引效率降低\****：虽然索引可以加速查询过程，但当IN子句中的元素非常多时，索引的效率会受到影响。因为数据库需要扫描索引中的大量条目来找到匹配项，这可能会导致索引的“深度”增加，从而降低查询速度。

**2.** ***\*资源消耗\****：

**o** ***\*内存和CPU占用高\****：大量元素的IN查询会占用更多的数据库内存和CPU资源，这可能会影响数据库服务器上其他并发查询的性能。

**o** ***\*网络带宽占用\****：在分布式数据库系统中，大量的查询数据可能需要通过网络传输，从而增加网络带宽的消耗。

**3.** ***\*数据库限制\****：

**o** ***\*参数数量限制\****：一些数据库管理系统（DBMS）对SQL语句中参数的数量有限制。如果IN子句中的元素数量超过了这些限制，那么查询将无法执行。

**o** ***\*查询长度限制\****：SQL语句的长度也受到DBMS的限制。当IN子句中的元素非常多时，整个查询语句可能会变得非常长，从而超过DBMS的限制。

**4.** ***\*优化困难\****：

**o** ***\*查询优化器限制\****：数据库查询优化器可能无法有效地优化包含大量元素的IN子句。这可能会导致查询执行计划不是最优的，从而进一步降低查询性能。

**o** ***\*替代方案复杂\****：为了绕过IN子句的限制，可能需要采用更复杂的查询策略，如使用临时表、子查询或分批查询等。这些替代方案可能会增加查询的复杂性和维护成本。

为了解决这些问题，可以考虑以下策略：

**·** ***\*分批查询\****：将大的IN子句拆分成多个小的IN子句，然后分别执行这些小的查询，并将结果合并。这种方法可以减少单个查询的复杂度，并提高整体性能。

**·** ***\*使用临时表\****：将需要查询的元素存储在一个临时表中，然后使用JOIN操作将临时表与原始表连接起来。这种方法可以避免IN子句中的元素数量限制，并可能提高查询性能。

**·** ***\*使用子查询\****：如果可能的话，将IN子句中的元素作为一个子查询的结果。这样，数据库可以优化子查询的执行计划，从而提高查询性能。

**·** ***\*优化数据模型\****：考虑是否可以通过优化数据模型来减少IN子句的使用。例如，可以通过添加额外的索引、调整表结构或使用更合适的数据类型来减少查询的复杂性和提高性能。

总之，当WHERE IN子句中的元素过多时，会面临性能下降、资源消耗增加、数据库限制以及优化困难等问题。为了解决这些问题，可以采取分批查询、使用临时表、子查询或优化数据模型等策略。

**10.** ***\*in和exitst的区别是什么\****

IN和EXISTS在SQL查询中都是用于检查子查询结果的谓词，但它们在语法、用途和性能优化方面存在显著差异。以下是它们之间的主要区别：

语法和用途

EXISTS：用于检查子查询中是否存在任何结果。其语法结构为EXISTS (子查询)。EXISTS不返回子查询中的具体数据，只返回一个布尔值（TRUE或FALSE），表示子查询是否返回了结果。它通常用于检查某个条件是否满足至少一个记录。

IN：用于检查指定列中的值是否包含在子查询返回的结果中。其语法结构为列 IN (子查询)或子查询 IN (列)（后者较少见）。IN返回满足条件的所有记录。

性能优化

EXISTS：在检查单个记录时通常更有效。当子查询返回的结果集很大，但只需要确认是否存在至少一个满足条件的记录时，EXISTS的性能优势尤为明显。因为它在找到第一个匹配项后就会停止处理子查询，不需要遍历整个结果集。

IN：在检查多个记录时可能更有效，特别是当子查询返回的结果集较小，且需要匹配多个值时。然而，当子查询返回大量数据时，IN的性能可能会下降，因为它需要遍历整个临时表（由子查询结果生成）来查找匹配项。

使用场景

EXISTS：适用于外查询表较小，而内查询表（子查询涉及的表）较大的情况。通过减少不必要的循环次数，可以提高查询效率。

IN：适用于外查询表较大，而内查询表较小的情况。通过先生成临时表并遍历它，可以减少对外查询表的遍历次数，从而提高效率。

返回值处理

EXISTS：如果子查询返回至少一个结果，则返回TRUE；如果子查询没有返回任何结果，则返回FALSE。如果子查询返回NULL，则EXISTS也返回FALSE。

IN：如果指定列中的值在子查询结果中，则返回该记录；如果子查询返回NULL，则IN表达式的结果也为NULL，这可能导致整个查询不返回任何结果（取决于查询的其他部分）。

示例

EXISTS示例：查询是否存在学生姓名为"John"的记录。

SELECT * FROM Students WHERE EXISTS (SELECT 1 FROM Students WHERE Name = 'John');

IN示例：查询学生姓名在特定列表中的记录（虽然这个例子用IN可能不是最优选择，因为它没有展示IN在处理大量数据时的优势）。

SELECT * FROM Students WHERE Name IN ('John', 'Jane', 'Doe');

综上所述，IN和EXISTS在SQL查询中各有其适用场景和性能特点。选择哪个取决于具体的查询需求、数据分布和性能考虑。

**11.** ***\*NULL引发的问题有哪些\****

查询复杂性增加：

当你在查询中包含NULL字段时，你可能需要使用IS NULL或IS NOT NULL条件来明确检查这些值。这增加了查询的复杂性，尤其是在涉及多个表和复杂连接时。默认情况下，NULL值在比较时被视为“未知”，这意味着NULL = NULL的结果是NULL（即未知），而不是TRUE。这可能会导致意外的查询结果，除非你明确使用IS NULL或IS NOT NULL。

索引效率降低：

虽然MySQL允许对包含NULL的列创建索引，但这些索引在某些情况下可能不如对非NULL列创建的索引高效。特别是，如果大多数行在索引列上都有NULL值，索引的过滤能力会显著降低。

对于复合索引，如果列中的NULL值较多，可能会降低索引的选择性和效率。

逻辑处理困难：

在应用逻辑中处理NULL值可能需要额外的注意和代码。例如，你可能需要编写特定的逻辑来确保NULL值不会导致错误（如除以NULL的错误）或产生意外的结果。

在编写存储过程、函数或触发器时，NULL值的行为可能需要仔细考虑，以确保逻辑的正确性。

数据完整性问题：

NULL值可能违反数据库中的某些完整性约束，特别是外键约束。如果外键列允许NULL值，那么这些值可能不与任何外键表中的行相关联，这可能导致数据不完整或不一致。

NULL值也可能违反非空（NOT NULL）约束，尽管这听起来有些自相矛盾，但在某些情况下（如尝试将NULL插入到标记为NOT NULL的列中）会引发错误。

性能问题：

在某些情况下，NULL值可能导致查询性能下降。这可能是因为MySQL需要额外的工作来处理NULL值的特殊情况，或者因为索引不能有效地过滤掉包含NULL的行。

频繁的NULL值更新可能导致索引碎片化，进一步影响性能。

**12.** ***\*vachar(10) char(10) int(10)的区别是怎么\****

 

 

 

 

**13.** ***\*left join\**** ***\*inner\**** ***\*join right join的区别是什么\****

![img](file:////Users/zhou/Library/Containers/com.kingsoft.wpsoffice.mac/Data/tmp/wps-zhou/ksohtml//wps24.jpg) 

 